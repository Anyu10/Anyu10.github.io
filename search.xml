<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Protocol Buffer</title>
    <url>/2023/01/20/Protocol-Buffer/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Go Compiler</title>
    <url>/2023/01/20/Go-Compiler/</url>
    <content><![CDATA[<h1 id="编译器和静态分析"><a href="#编译器和静态分析" class="headerlink" title="编译器和静态分析"></a>编译器和静态分析</h1><h2 id="编译器的结构"><a href="#编译器的结构" class="headerlink" title="编译器的结构"></a>编译器的结构</h2><p><img src="D:\Blog\source_images\image-20230120191244188.png" alt="img"></p>
<ul>
<li>分析部分 (front end)<ul>
<li>词法分析 –&gt; 词素(lexeme)</li>
<li>语法分析 –&gt; 抽象语法树(AST, Abstract Syntax Tree)</li>
<li>语义分析，收集类型信息，进行语义检查 –&gt; decorated AST</li>
<li>中间代码生成 –&gt; Intermediate Representation(IR) <ul>
<li>IR 是<strong>机器无关</strong>的</li>
</ul>
</li>
</ul>
</li>
<li>综合部分 (back end)<ul>
<li>代码优化(<strong>机器无关</strong>) –&gt; optimized IR</li>
<li>代码生成 –&gt; 目标代码</li>
</ul>
</li>
</ul>
<h2 id="静态分析"><a href="#静态分析" class="headerlink" title="静态分析"></a>静态分析</h2><p>静态分析通常用于<strong>后端代码优化</strong></p>
<p>不执行程序代码，推导程序的行为，分析程序的性质，根据这些性质优化代码</p>
<ul>
<li>控制流分析 (Control Flow): 程序执行的流程</li>
<li>数据流分析 (Data Flow): 数据在控制流上的传递</li>
</ul>
<p>分析方式：</p>
<ul>
<li>过程内分析 (Intra-procedural analysis): 仅在函数内分析</li>
<li>过程间分析 (Inter-procedural analysis): 考虑函数调用时的参数传递和返回值的控制流和数据流<ul>
<li>过程间分析比较复杂，需要综合数据流和控制流</li>
</ul>
</li>
</ul>
<h1 id="Go-编译器优化"><a href="#Go-编译器优化" class="headerlink" title="Go 编译器优化"></a>Go 编译器优化</h1><p>Go 编译器为了追求编译的速度，编译器的优化较少</p>
<p>一些优化方向：</p>
<ul>
<li>函数内联</li>
<li>逃逸分析</li>
<li>默认栈大小调整</li>
<li>循环展开</li>
<li>边界检查消除</li>
</ul>
<h2 id="函数内联-Function-Inlining"><a href="#函数内联-Function-Inlining" class="headerlink" title="函数内联 (Function Inlining)"></a>函数内联 (Function Inlining)</h2><p>内联：将callee的副本替换到caller的位置，同时<strong>重写代码以反映参数的传递</strong></p>
<p>优点：</p>
<ul>
<li>消除调用开销，例如传参，保存寄存器等</li>
<li><strong>将过程间分析转化为过程内分析</strong>，帮助其他优化，例如<strong>逃逸分析</strong></li>
</ul>
<p>缺点：</p>
<ul>
<li>函数体变大，对 instruction cache (icache) 不友好</li>
<li>编译生成的 go 镜像变大</li>
</ul>
<p>函数内联大多数情况下是正优化</p>
<p>内联策略：调用和被调用函数的规模</p>
<h2 id="内联优化"><a href="#内联优化" class="headerlink" title="内联优化"></a>内联优化</h2><p>Go函数内联受到的限制多：interface，defer等语言特性限制了内联，内联策略非常保守</p>
<p>优化：调整函数内联的策略</p>
<h2 id="逃逸分析-Escape-Analysis"><a href="#逃逸分析-Escape-Analysis" class="headerlink" title="逃逸分析 (Escape Analysis)"></a>逃逸分析 (Escape Analysis)</h2><p>分析代码中指针的动态作用域：指针在何处能被访问</p>
<p>大致思路：</p>
<ul>
<li>从对象被分配处出发，沿着控制流观察对象的数据流：</li>
<li>若发现指针 p 在当前作用域 s 的时候：<ul>
<li>作为参数传递给别的函数</li>
<li>传递给全局变量</li>
<li>传递给其他goroutine</li>
<li>传递给已逃逸的指针指向的对象</li>
</ul>
</li>
<li>则指针 p 逃逸出了 s，反之没有逃逸出 s</li>
</ul>
<h2 id="逃逸优化"><a href="#逃逸优化" class="headerlink" title="逃逸优化"></a>逃逸优化</h2><p><strong>函数内联拓展了函数的边界，更多对象不逃逸</strong></p>
<p>未逃逸的对象可以栈上分配</p>
<ul>
<li>栈的分配和回收速度很快：移动sp</li>
<li>减少在heap上的分配，减轻GC的负担</li>
</ul>
]]></content>
      <tags>
        <tag>Go</tag>
        <tag>Compiler</tag>
      </tags>
  </entry>
  <entry>
    <title>Go Memory</title>
    <url>/2023/01/20/Go-Memory/</url>
    <content><![CDATA[<h1 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h1><h2 id="软件结构"><a href="#软件结构" class="headerlink" title="软件结构"></a>软件结构</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TB</span><br><span class="line">业务代码 --&gt; SDK --&gt; 基础库 --&gt; 语言runtime --&gt; OS</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h2 id="性能优化-1"><a href="#性能优化-1" class="headerlink" title="性能优化"></a>性能优化</h2><p>业务优化，runtime优化，SDK优化</p>
<p>数据驱动</p>
<ul>
<li>自动化性能分析工具 – pprof</li>
<li>依靠数据而非猜测</li>
<li>首先优化最大瓶颈</li>
</ul>
<p><img src="D:\Blog\source_images\image-20230120155529260.png" alt="image-20230120155529260"></p>
<p>性能优化和软件质量：</p>
<ul>
<li>保证<strong>接口稳定</strong>前提的情况下改进具体实现</li>
<li><strong>测试驱动开发</strong>：Test Driven Development</li>
<li><strong>文档</strong>：描述优化，做了什么，达到什么效果</li>
<li><strong>隔离性</strong>：通过选项控制是否开启优化</li>
<li><strong>可观测</strong>：必要的日志输出</li>
</ul>
<h1 id="Auto-Memory-Management"><a href="#Auto-Memory-Management" class="headerlink" title="Auto Memory Management"></a>Auto Memory Management</h1><h2 id="Concept"><a href="#Concept" class="headerlink" title="Concept"></a>Concept</h2><p><strong>自动内存管理</strong>管理的是<strong>动态内存</strong>(运行时根据需求动态分配的内存)： <code>malloc()</code></p>
<p>自动内存管理: 由程序语言的 runtime 系统管理动态内存</p>
<ul>
<li>保证内存使用的<em>正确性</em>和<em>安全性</em>: double-free problem, use-after-free problem</li>
<li>避免手动内存管理</li>
</ul>
<p>自动内存管理的三个任务：</p>
<ul>
<li>为对象分配新空间</li>
<li>找到存活的对象</li>
<li>回收死亡对象的内存空间</li>
</ul>
<p>线程类型</p>
<ul>
<li><p>Mutator thread: 业务线程，分配新对象，修改对象指向关系</p>
</li>
<li><p>Collector thread: GC线程，找到存活对象，回收死亡对象的内存空间</p>
</li>
</ul>
<p>GC分类：</p>
<ul>
<li>Serial GC: 只有一个Collector线程</li>
<li>Parallel GC: 支持多个Collector同时回收的GC算法</li>
<li>Concurrent GC: Mutators threads 和 Collector threads 可以同时执行<ul>
<li><strong>Collectors必须感知对象指向关系的改变</strong>，例如在GC过程中，Mutator线程修改了对象的指向关系</li>
</ul>
</li>
</ul>
<p><img src="D:\Blog\source_images\image-20230120160944188.png" alt="image-20230120160944188"></p>
<p>GC算法的评价：</p>
<ul>
<li>安全性(safety)：不能回收存活的对象</li>
<li>吞吐率(throughput)：$1-\frac{time_{GC}}{time_{total}}$</li>
<li>暂停时间(pause time): stop the world(STW) 业务是否感知的到</li>
<li>内存开销(space overhead): GC metadata overhead</li>
</ul>
<h2 id="Tracing-Garbage-Collection"><a href="#Tracing-Garbage-Collection" class="headerlink" title="Tracing Garbage Collection"></a>Tracing Garbage Collection</h2><h3 id="Collection-Strategy"><a href="#Collection-Strategy" class="headerlink" title="Collection Strategy"></a>Collection Strategy</h3><p>对象回收的条件：指针指向不可达的对象可以被回收</p>
<p>回收过程：</p>
<ol>
<li><p>标记根对象</p>
<ul>
<li>根对象包括：静态变量、全局变量、常量、线程栈</li>
</ul>
</li>
<li><p>标记可达对象</p>
<ul>
<li>求指针指向关系的传递闭包，找到所有的可达对象</li>
</ul>
</li>
<li><p>清理不可达对象</p>
<ul>
<li><p>将存活对象复制到另外的内存空间 (<strong>Copying GC</strong>)</p>
<p><img src="D:\Blog\source_images\image-20230120162342068.png" alt="image-20230120162342068"></p>
</li>
<li><p>将死亡对象标记为可分配，用 free-list 管理 (<strong>Mark-Sweep GC</strong>)</p>
<p><img src="C:\Users\Anyu\AppData\Roaming\Typora\typora-user-images\image-20230120162436503.png" alt="image-20230120162436503"></p>
</li>
<li><p>移动并整理存活对象，根据一定的策略做压缩 (Mark-Compact GC)</p>
<p><img src="D:\Blog\source_images\image-20230120162602987.png" alt="image-20230120162602987"></p>
</li>
</ul>
</li>
<li><p>根据对象不同的生命周期，采取不同的回收策略</p>
</li>
</ol>
<h3 id="Generational-GC"><a href="#Generational-GC" class="headerlink" title="Generational GC"></a>Generational GC</h3><p>分代假说 (Generational Hypothesis): 很多对象很快就死亡了</p>
<ul>
<li>Intuition: 很多对象分配之后就很快不适用了</li>
</ul>
<p>每个对象都有年龄，年龄即为经历过GC的次数</p>
<ul>
<li>区别年轻代和老年的对象，使用不同的策略</li>
<li>年轻代 (Young Generation)<ul>
<li>常规的对象分配，存活对象很少</li>
<li>采用<strong>copying GC</strong></li>
<li>GC吞吐率高</li>
</ul>
</li>
<li>老年代 (Old Generation)<ul>
<li>对象趋向于一直活着，反复复制的开销很大</li>
<li>可以采用<strong>mark-sweep GC</strong></li>
</ul>
</li>
</ul>
<h2 id="Referencing-Counting"><a href="#Referencing-Counting" class="headerlink" title="Referencing Counting"></a>Referencing Counting</h2><p>基本思路：</p>
<ul>
<li>每个对象都有一个与之关联的引用计数</li>
<li>对象的存活条件：当且仅当引用计数大于0</li>
</ul>
<p>优点：</p>
<ul>
<li>内存管理操作被平摊到了程序执行过程中</li>
<li>内存管理不需要了解runtime的实现细节，例如 C++ 中的 smart pointer，Rust 中的 ownership 和 lifetime</li>
</ul>
<p>缺点：</p>
<ul>
<li>维护开销大，需要通过<strong>原子操作</strong>保证引用计数操作的唯一性和可见性</li>
<li>无法回收<strong>环形的不可达数据结构</strong> –&gt; 可通过 weak reference 解决</li>
<li>内存开销大，每个对象都需要额外的空间记录引用计数</li>
<li>回收内存时依然<strong>可能引入暂停</strong> –&gt; 例如回收一个很大的链表</li>
</ul>
<h1 id="Go-内存管理"><a href="#Go-内存管理" class="headerlink" title="Go 内存管理"></a>Go 内存管理</h1><h2 id="Go-内存分配"><a href="#Go-内存分配" class="headerlink" title="Go 内存分配"></a>Go 内存分配</h2><p>目标：为对象在 heap 上分配内存</p>
<h3 id="分块"><a href="#分块" class="headerlink" title="分块"></a>分块</h3><ul>
<li>提前为内存<strong>分块</strong>:<ol>
<li>调用 <code>mmap()</code> 向OS申请一大块内存，例如4MB</li>
<li>将内存分为大块，如 8KB，称为<em>mspan</em></li>
<li>再将mspan分为特定大小的小块，用于对象分配</li>
<li><strong>nonscan mspan</strong>: 不包含指针的对象 – <strong>GC不需要扫描</strong></li>
<li><strong>scan mspan</strong>: 包含指针的对象 – <strong>GC需要扫描</strong></li>
</ol>
</li>
<li>对象分配：根据块大小，分配最适合的块</li>
</ul>
<h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><ul>
<li>TCMalloc: thread caching</li>
<li>每个p包含一个 mcache 用于快速分配，用于绑定于 p 上的 g 分配对象</li>
<li>mcache 管理一组 mspan</li>
<li>mcache 已满时，mcache 向 mcentral 申请带有未分配块的 mspan</li>
<li>当 mspan 没有对象的时候，mspan 会先被缓存在 mcentral 中，而不是立刻释放给 OS</li>
</ul>
<p><img src="D:\Blog\source_images\image-20230120165816117.png" alt="image-20230120165816117"></p>
<h2 id="内存分配的优化"><a href="#内存分配的优化" class="headerlink" title="内存分配的优化"></a>内存分配的优化</h2><h3 id="Observation"><a href="#Observation" class="headerlink" title="Observation"></a>Observation</h3><ol>
<li>对象分配是<strong>高频</strong>的操作: 每秒GB级别的对象分配</li>
<li><strong>小对象</strong>占比例比较高 –&gt; 对小对象可以进行特定的优化</li>
<li>Go内存分配比较耗时<ul>
<li>分配路径较长: <code>g -&gt; m -&gt; p -&gt; mcache -&gt; mspan -&gt; memory block -&gt; return pointer</code></li>
<li>pprof: 对象分配的函数是最频繁调用的函数之一</li>
</ul>
</li>
</ol>
<h3 id="小对象内存分配优化方案-–-Balanced-GC"><a href="#小对象内存分配优化方案-–-Balanced-GC" class="headerlink" title="小对象内存分配优化方案 – Balanced GC"></a>小对象内存分配优化方案 – Balanced GC</h3><ul>
<li>将 noscan 对象在 per-g allocation buffer (GAB) 上分配，并使用移动对象 GC 管理这部分内存，提高对象分配和回收效率<ul>
<li>每个 g 会附加一个较大的 allocation buffer (例如1KB) 用来分配小于128B的 nonscan 小对象</li>
</ul>
</li>
<li><strong>bump pointer 风格</strong>的对象分配。<ul>
<li>分配对象时，根据对象大小移动 <code>top</code> 指针并返回，快速完成一次对象分配</li>
<li>同原先调用 <code>mallocgc()</code> 进行对象分配的方式相比，balanced GC <strong>缩短了对象分配的路径</strong>，降低 CPU 使用</li>
</ul>
</li>
<li>从 Go runtime 内存管理模块的角度看，一个 allocation buffer 其实是一个大对象。本质上 balanced GC 是<strong>将多次小对象的分配合并成一次大对象的分配</strong>。<ul>
<li>存在问题：当 GAB 中哪怕只有一个小对象存活时，Go runtime 也会认为整个大对象（即 GAB）存活。</li>
<li>解决方案：balanced GC 会根据 GC 策略，<strong>将 GAB 中存活的对象移动到另外的 GAB 中</strong>，从而压缩并清理 GAB 的内存空间，原先的 GAB 空间由于不再有存活对象，可以全部释放，如下图所示。<img src="D:\Blog\source_images\image-20230120171942068.png" alt="img"></li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>Go</tag>
        <tag>Memory</tag>
      </tags>
  </entry>
  <entry>
    <title>Go-Style</title>
    <url>/2023/01/19/Go-Style/</url>
    <content><![CDATA[<h1 id="高质量编码"><a href="#高质量编码" class="headerlink" title="高质量编码"></a>高质量编码</h1><p>什么是高质量？</p>
<ul>
<li>考虑到edge case</li>
<li>异常状况处理，稳定性</li>
<li>易读易维护，易于重构</li>
</ul>
<span id="more"></span>

<p>编程原则？</p>
<ul>
<li>简单性 - 消除多余的复杂性，否则代码难以维护</li>
<li>可读性 - 保证代码的可维护性</li>
<li>生产力 - 团队的整体工作效率</li>
</ul>
<h1 id="编码规范"><a href="#编码规范" class="headerlink" title="编码规范"></a>编码规范</h1><h2 id="代码格式"><a href="#代码格式" class="headerlink" title="代码格式"></a>代码格式</h2><ul>
<li><p>gofmt</p>
</li>
<li><p>goimports</p>
</li>
</ul>
<h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><p><strong>公共符号必须要使用注释</strong></p>
<ul>
<li>代码作用</li>
<li>代码如何做的</li>
<li>代码实现的原因</li>
<li>什么情况会出错</li>
</ul>
<h2 id="命名规范"><a href="#命名规范" class="headerlink" title="命名规范"></a>命名规范</h2><p>Variable：</p>
<ul>
<li>简洁胜于冗长</li>
<li>缩略词全大写，但位于变量开头的时候全小写<ul>
<li>例如ServeHTTP instead of ServeHttp</li>
<li>xmlHTTPRequest 或 XMLHTTPRequest</li>
</ul>
</li>
<li>变量距离使用的距离越远，则需要携带越多的上下文信息<ul>
<li>全局变量要在名字中体现出更多的上下文信息，使得可以辨别其含义</li>
</ul>
</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Bad</span></span><br><span class="line"><span class="keyword">for</span> index := <span class="number">0</span>; index &lt; n; index++ &#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Good</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; n; i++ &#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// Bad</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Client)</span></span> send(req *Request, t time.Time)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Good, deadline has more semantics</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Client)</span></span> send(req *Request, deadline time.Time)</span><br></pre></td></tr></table></figure>

<p>Function:</p>
<ul>
<li>函数名不需要携带包信息，因为包名和函数名总是成对出现的</li>
<li>函数名应该尽量简短</li>
<li>当包名和函数的返回类型一样时，可以省略类型信息</li>
<li>当包名和函数的返回类型不一样时，可以在函数名中加入类型信息</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> http</span><br><span class="line"></span><br><span class="line"><span class="comment">// Good</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Serve</span><span class="params">(l net.Listener, handler Handler)</span></span> <span class="type">error</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Bad, http.ServeHTTP when invoking, which is verbose</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ServeHTTP</span><span class="params">(l net.Listener, handler Handler)</span></span> <span class="type">error</span></span><br></pre></td></tr></table></figure>

<p>Package:</p>
<ul>
<li>小写字母组成，不包含大写字母和下划线</li>
<li>简短并包含上下文信息</li>
<li>不与标准库同名</li>
</ul>
<p>其他规则：</p>
<ul>
<li>不使用常用变量作为包名，例如bufio而不是buf</li>
<li>使用单数而不使用复数，例如encoding而不是encodings</li>
<li>谨慎使用缩写</li>
</ul>
<h2 id="控制流程"><a href="#控制流程" class="headerlink" title="控制流程"></a>控制流程</h2><p>避免嵌套，保证正常流程清晰</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Bad</span></span><br><span class="line"><span class="keyword">if</span> foo &#123;</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Good, 分支中包含多个return语句，可以去除冗余的分支</span></span><br><span class="line"><span class="keyword">if</span> foo &#123;</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br></pre></td></tr></table></figure>

<p>尽量保持正常代码路径为最小缩进</p>
<ul>
<li>优先处理错误和特殊情况，尽早返回或继续循环以减少嵌套</li>
<li>线性原理，逻辑尽量走直线，避免复杂的嵌套分支</li>
<li>正常流程代码沿屏幕往下流动</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Bad</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">OneFunc</span><span class="params">()</span></span> <span class="type">error</span> &#123;</span><br><span class="line">    err := DoSomething()</span><br><span class="line">    <span class="keyword">if</span> err == <span class="literal">nil</span> &#123;</span><br><span class="line">        err = DoAnotherThing()</span><br><span class="line">        <span class="keyword">if</span> err == <span class="literal">nil</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">nil</span>	<span class="comment">// normal case</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> err</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//Good</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">OneFunc</span><span class="params">()</span></span> <span class="type">error</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> err := DoSomething(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> err</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> err := DoAnotherThing(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> err</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="错误与异常处理"><a href="#错误与异常处理" class="headerlink" title="错误与异常处理"></a>错误与异常处理</h2><p>简单错误：</p>
<ul>
<li>指仅出现一次的错误，且<strong>其他地方不需要捕获该错误</strong></li>
<li>优先使用 <code>errors.New</code> 创建匿名变量来表示简单错误</li>
<li>如果有格式化需求可以使用 <code>fmt.Errorf</code></li>
</ul>
<p>错误的Wrap和Unwrap</p>
<ul>
<li>在 <code>fmt.Errorf</code> 中使用 <code>%w</code> 关键字来将一个错误 wrap 至其错误链中</li>
<li>错误的 wrap 实际上提供了一个 error 嵌套另一个 error 的功能，从而生成 error 的跟踪链条，以方便判断错误</li>
</ul>
<p>错误判定</p>
<ul>
<li>判断一个错误链是否包含一个特定的错误，使用 <code>errors.Is</code> 的方法</li>
<li>获取特定种类的错误，使用 <code>errors.As</code> 方法</li>
</ul>
<p>Panic：</p>
<ul>
<li>不建议在业务代码中使用 panic</li>
<li>建议使用 error 代替 panic</li>
<li>程序启动阶段发生不可逆转的作用的时候，可以在 init 或 main 中使用 panic， 尽早暴露错误</li>
</ul>
<p>Recovery：</p>
<ul>
<li>通常在recovery中打印出panic时的调用堆栈 <code>debug.Stack()</code></li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *treeFS)</span></span> Open(name <span class="type">string</span>) (f fs.File, err <span class="type">error</span>) &#123;</span><br><span class="line">    <span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">if</span> e := <span class="built_in">recover</span>(); e != <span class="literal">nil</span> &#123;</span><br><span class="line">            f = <span class="literal">nil</span></span><br><span class="line">            err = fmt.Errorf(<span class="string">&quot;git fs panics: %v\n%s&quot;</span>, e, debug.Stack())</span><br><span class="line">        &#125;</span><br><span class="line">	&#125;()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>小结：</p>
<ul>
<li>error 应提供上下文信息链，方便定位</li>
<li>panic用于定位真正异常的情况</li>
</ul>
<h1 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h1><h2 id="Slice"><a href="#Slice" class="headerlink" title="Slice"></a>Slice</h2><p>Slice预分配内存</p>
<ul>
<li>尽可能使用 <code>make()</code> 初始化切片时提供容量信息</li>
</ul>
<p>Slice大内存未释放</p>
<ul>
<li>在已有的切片上创建切片，不会创建新的底层数组，且原来的切片存在引用，不会被释放</li>
<li>可以使用 copy 代替 re-slice</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Bad</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GetLastBySlice</span><span class="params">(origin []<span class="type">int</span>)</span></span> []<span class="type">int</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> origin[<span class="built_in">len</span>(origin)<span class="number">-2</span>:]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Good</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GetLastBySlice</span><span class="params">(origin []<span class="type">int</span>)</span></span> []<span class="type">int</span> &#123;</span><br><span class="line">    res := <span class="built_in">make</span>([]<span class="type">int</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="built_in">copy</span>(res, origin[<span class="built_in">len</span>(origin)<span class="number">-2</span>:])</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><p>Map预分配内存</p>
<ul>
<li>不断向 map 添加元素会触发map扩容</li>
<li>提前分配空间可以避免 re-hash 和扩容</li>
</ul>
<h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><p>字符串处理：</p>
<ul>
<li>strings.Builder &gt; bytes.Buffer &gt; +</li>
<li>strings.Builder 和 bytes.Buffer 均使用了 []byte 类型作为底层存储结构</li>
<li>strings.Builder 直接将底层的 []byte 结构转化为了字符串类型返回，而 bytes.Buffer 在转换字符串的时候重新申请了一片空间因此 strings.Builder 比 bytes.Buffer 略快</li>
<li><strong>已知字符串长度的时候，可以通过 <code>Grow</code> 预分配空间更进一步提升性能</strong></li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">preStrBuilder</span><span class="params">(n <span class="type">int</span>, str <span class="type">string</span>)</span></span> <span class="type">string</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> buidler strings.Builder</span><br><span class="line">    builder.Grow(n * <span class="built_in">len</span>(str))	<span class="comment">// similar to bytes.Buffer.Grow</span></span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(str); i++ &#123;</span><br><span class="line">        builder.WriteString(str)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> builder.String()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Empty-Struct"><a href="#Empty-Struct" class="headerlink" title="Empty Struct"></a>Empty Struct</h2><p>使用空结构体节省内存</p>
<ul>
<li><code>struct&#123;&#125;&#123;&#125;</code> 不占内存空间</li>
<li>可以作为占位符使用，并且具有一定的语义</li>
</ul>
<h2 id="Atomic"><a href="#Atomic" class="headerlink" title="Atomic"></a>Atomic</h2><p>使用 atomic 包</p>
<ul>
<li>锁通过系统调用实现，成本较高</li>
<li>atomic操作由硬件实现，性能较好</li>
<li>非数值操作可以使用 <code>atomic.Value</code>, 能承载一个 <code>interface&#123;&#125;</code></li>
</ul>
]]></content>
      <tags>
        <tag>Go</tag>
        <tag>Style</tag>
      </tags>
  </entry>
  <entry>
    <title>Go-Profile</title>
    <url>/2023/01/19/Go-Profile/</url>
    <content><![CDATA[<h1 id="性能调优准则"><a href="#性能调优准则" class="headerlink" title="性能调优准则"></a>性能调优准则</h1><ul>
<li>要依靠<strong>数据</strong>而不是猜测</li>
<li>要定位到<strong>最大瓶颈</strong>，而不是细枝末节</li>
<li>不要过早优化</li>
<li>不要过度优化</li>
</ul>
<span id="more"></span>

<h1 id="性能分析工具pprof"><a href="#性能分析工具pprof" class="headerlink" title="性能分析工具pprof"></a>性能分析工具pprof</h1><h2 id="功能简介"><a href="#功能简介" class="headerlink" title="功能简介"></a>功能简介</h2><p><img src="D:\Blog\source_images\image-20230119214436210.png" alt="image-20230119214436210"></p>
<h2 id="CPU性能分析"><a href="#CPU性能分析" class="headerlink" title="CPU性能分析"></a>CPU性能分析</h2><p>使用命令 <code>go tool pprof &quot;localhost:6060/debug/pprof/profile?seconds=10&quot;</code> 采集10s的数据，并进入可交互的终端</p>
<ul>
<li><code>top[N]</code>: 查看占用资源最多的函数<ul>
<li>flat: 当前函数<strong>本身</strong>的执行耗时 </li>
<li>flat%: 执行耗时占的百分比</li>
<li>sum%: 该函数及其之上的函数占的总百分比</li>
<li>cum: 当前函数<strong>及其调用函数</strong>的总执行耗时</li>
<li>cum%: 总执行耗时的百分比</li>
<li>flat &#x3D;&#x3D; cum –&gt; 函数中没有调用其他函数</li>
<li>flat &#x3D;&#x3D; 0 –&gt; 函数中只有其他函数的调用</li>
</ul>
</li>
<li><code>list [regexp]</code>: 根据正则表达式查找代码行</li>
<li><code>web</code>: 调用关系可视化</li>
</ul>
<h2 id="堆分析"><a href="#堆分析" class="headerlink" title="堆分析"></a>堆分析</h2><p>使用 <code>go tool pprof -http=:8080 &quot;http://localhost:6060/debug/pprof/heap&quot;</code> 命令，在localhost:8080地址展示各种视图和工具进行分析</p>
<h2 id="其他分析"><a href="#其他分析" class="headerlink" title="其他分析"></a>其他分析</h2><p>协程分析：<code>go tool pprof -http=:8080 &quot;http://localhost:6060/debug/pprof/goroutine&quot;</code></p>
<p>锁分析：<code>go tool pprof -http=:8080 &quot;http://localhost:6060/debug/pprof/mutex&quot;</code></p>
<p>阻塞分析：<code>go tool pprof -http=:8080 &quot;http://localhost:6060/debug/pprof/block&quot;</code></p>
<h2 id="剖析"><a href="#剖析" class="headerlink" title="剖析"></a>剖析</h2><p>通过 <code>go test</code> 命令可以指定生成测试程序的 profile，这些profile可以用来分析 cpu, block, mem 等性能</p>
<p>例如</p>
<ul>
<li>CPU分析<ul>
<li><code>go test -cpuprofile=cpu.log module/package</code> </li>
<li><code>go tool pprof -http=:8080 cpu.log</code></li>
</ul>
</li>
<li>block分析<ul>
<li><code>go test -blockprofile=block.log module/package</code></li>
<li><code>go tool pprof -http=:8080 block.log</code></li>
</ul>
</li>
<li>mem分析<ul>
<li><code>go test -memprofile=block.log module/package</code></li>
<li><code>go tool pprof -http=:8080 mem.log</code></li>
</ul>
</li>
</ul>
<h1 id="pprof原理和采样过程"><a href="#pprof原理和采样过程" class="headerlink" title="pprof原理和采样过程"></a>pprof原理和采样过程</h1><h2 id="CPU采样"><a href="#CPU采样" class="headerlink" title="CPU采样"></a>CPU采样</h2><ul>
<li>操作系统定时器：启动一个操作系统的定时器，每10ms发送一个SIGPROF信息给进程</li>
<li>进程堆栈：进程<strong>每次收到SIGPROF信号都记录调用堆栈</strong></li>
<li>写缓冲：每100ms读取记录的调用堆栈并写入到输出流</li>
</ul>
<h2 id="Heap采样"><a href="#Heap采样" class="headerlink" title="Heap采样"></a>Heap采样</h2><ul>
<li>采样程序通过<strong>内存分配器</strong>在堆上分配和释放的内存，<strong>记录分配&#x2F;释放的大小和数量</strong></li>
<li>采样率：<strong>每512KB采样一次</strong>，可在运行开头修改，1表示每次分配均记录</li>
<li>采样时间：程序开始运行时到采样时</li>
<li>采样指标：alloc_space, alloc_objects, inuse_space, inuse_objects</li>
<li>inuse&#x3D;alloc-free</li>
</ul>
<h2 id="Goroutine-amp-ThreadCreate-采样"><a href="#Goroutine-amp-ThreadCreate-采样" class="headerlink" title="Goroutine &amp; ThreadCreate 采样"></a>Goroutine &amp; ThreadCreate 采样</h2><ul>
<li>Goroutine<ul>
<li>记录所有用户发起的且在运行中的goroutine(<strong>即入口非runtime开头的goroutine</strong>)runtime.main的调用栈信息</li>
</ul>
</li>
<li>ThreadCreate<ul>
<li>记录程序创建的所有系统线程的信息</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph LR</span><br><span class="line">direction LR</span><br><span class="line">id1(stop the world) --&gt; id2(遍历allg切片) --&gt; id3(输出创建g的堆栈) --&gt; id4(start the world)</span><br></pre></td></tr></table></figure>

<h2 id="Block-amp-Mutex-采样"><a href="#Block-amp-Mutex-采样" class="headerlink" title="Block &amp; Mutex 采样"></a>Block &amp; Mutex 采样</h2><ul>
<li>Block采样<ul>
<li>采样阻塞操作的次数和耗时</li>
<li>采样率：阻塞耗时超过阈值才会被记录，也可以设置采样率，1表示每次都记录</li>
</ul>
</li>
<li>锁竞争<ul>
<li>采样争抢锁的次数和耗时</li>
<li>采样率：只记录固定比例的锁操作，也可以设置采样率，1表示每次都记录</li>
</ul>
</li>
</ul>
<h1 id="性能调优"><a href="#性能调优" class="headerlink" title="性能调优"></a>性能调优</h1><h2 id="业务服务优化"><a href="#业务服务优化" class="headerlink" title="业务服务优化"></a>业务服务优化</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>服务：能<strong>单独部署</strong>，承载<strong>一定功能</strong>的程序</p>
<p>依赖：Service A的功能实现依赖Service B的响应结果，则Service A依赖Service B</p>
<p>调用链路：支持一个接口的相关服务集合及其相互之间的依赖关系</p>
<p>基础库：公共的工具包，中间件</p>
<h3 id="单体Service优化流程"><a href="#单体Service优化流程" class="headerlink" title="单体Service优化流程"></a>单体Service优化流程</h3><ol>
<li>建立服务性能的<strong>评估手段</strong><ul>
<li>Benchmark</li>
<li>Others</li>
</ul>
</li>
<li>分析性能数据，定义<strong>性能瓶颈</strong></li>
<li>优化代码，消除瓶颈</li>
<li>验证优化效果</li>
</ol>
<h4 id="评估手段"><a href="#评估手段" class="headerlink" title="评估手段"></a>评估手段</h4><ul>
<li>不同负载性能表现有差异</li>
<li>不同请求参数覆盖的逻辑不同，请求流量不同</li>
<li>压测范围<ul>
<li>单机压测</li>
<li>集群压测</li>
</ul>
</li>
<li>性能数据采集<ul>
<li>单机性能数据</li>
<li>集群性能数据</li>
</ul>
</li>
</ul>
<h4 id="性能瓶颈"><a href="#性能瓶颈" class="headerlink" title="性能瓶颈"></a>性能瓶颈</h4><ul>
<li>使用库不规范</li>
<li>高并发场景优化不足，例如异步log</li>
</ul>
<h4 id="验证结果"><a href="#验证结果" class="headerlink" title="验证结果"></a>验证结果</h4><ul>
<li>正确性<ul>
<li><strong>确保正确性</strong></li>
<li>响应数据diff</li>
</ul>
</li>
<li>重复压测验证</li>
<li>上线后评估优化效果<ul>
<li>关注监控</li>
<li>收集性能数据</li>
<li>逐步放量</li>
</ul>
</li>
</ul>
<h3 id="服务链路性能优化"><a href="#服务链路性能优化" class="headerlink" title="服务链路性能优化"></a>服务链路性能优化</h3><p>分析链路</p>
<h2 id="基础库优化"><a href="#基础库优化" class="headerlink" title="基础库优化"></a>基础库优化</h2><ol>
<li>分析基础库核心逻辑和性能瓶颈<ul>
<li>设计完善的改造方案</li>
<li>数据按需获取</li>
<li>序列化反序列化优化</li>
</ul>
</li>
<li>内部压测验证</li>
<li>推广业务服务落地验证</li>
</ol>
<h2 id="Go语言优化"><a href="#Go语言优化" class="headerlink" title="Go语言优化"></a>Go语言优化</h2><p>编译器 &amp; 运行时优化</p>
<ul>
<li>优化<strong>内存分配策略</strong></li>
<li>优化代码<strong>编译流程</strong>，生成更高效的程序</li>
</ul>
]]></content>
      <tags>
        <tag>Go</tag>
        <tag>Profile</tag>
      </tags>
  </entry>
  <entry>
    <title>GFS</title>
    <url>/2022/12/17/GFS/</url>
    <content><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Big storage abstraction is important in distributed systems.</p>
<p>Why is it hard?</p>
<ul>
<li>Performance –&gt; Sharding</li>
<li>Faults –&gt; Tolerance</li>
<li>Tolerance –&gt; Replication</li>
<li>Replication –&gt; Consistency</li>
<li>Consistency –&gt; Low Performance</li>
</ul>
<span id="more"></span>

<p>Why we need GFS?</p>
<ul>
<li>A strawman replication design:</li>
</ul>
<p><img src="D:\Blog\source_images\repl.drawio.png" alt="repl.drawio"></p>
<ul>
<li>User1 write 1 to two machines, User2 write 2 to two machines</li>
<li>Due to the network, server1 see 2 first; server2 see 1 first.</li>
<li>Consistency is destroyed!</li>
</ul>
<p>How about GFS?</p>
<ul>
<li>Performance: Sharding, every file will be automatically sharded by GFS.</li>
<li>Performance: it has high aggregate performance to a large number of clients. </li>
<li>Fault Tolerance: Automatic failure recovery.</li>
<li>Designed for a single datacenter.</li>
<li>Designed for big sequential access.</li>
<li>Designed for data-intensive applications.</li>
</ul>
<p>What problem does GFS solve?</p>
<ul>
<li>Component failures are norm rather than exception<ul>
<li>Constant monitoring, error detection, fault tolerance, and automatic recovery are needed.</li>
</ul>
</li>
<li>Files are huge, so it’s unwieldy to manage billions of KB-sized files.<ul>
<li>Design choices of I&#x2F;O operation and block sizes have to be revisited.</li>
</ul>
</li>
<li>Appending and sequential reading are more common than write operation.<ul>
<li>Appending become the focus of optimization and atomicity guarantee instead of caching data blocks in the client (like what normal filesystems do).</li>
</ul>
</li>
<li>Co-designing the applications and the file system API, relaxing GFS’s consistency model, and designing an atomic append operation.</li>
</ul>
<h1 id="Design"><a href="#Design" class="headerlink" title="Design"></a>Design</h1><h2 id="Assumption"><a href="#Assumption" class="headerlink" title="Assumption"></a>Assumption</h2><ul>
<li>System is built from inexpensive components that <em>usually fails</em> –&gt; so it needs monitor and detect, tolerate and recovery from component failure.</li>
<li>System stores mostly large files. <em>Large files operations</em> should be efficient.</li>
<li>Two kinds of reads: <strong>large streaming read</strong> and <strong>small random reads</strong>.<ul>
<li>Performance-conscious applications often batch and sort small reads to advance steadily through the file rather than go back and forth.</li>
</ul>
</li>
<li>Two kinds of writes: <strong>large, sequential writes that append data to files</strong> (normal and need to be optimized) and <strong>small writes at random positions</strong> (rare and need not to be efficient).</li>
<li>Should support well-defined semantic of <em>appending files concurrently</em> –&gt; Atomicity with minimal synchronization overhead is needed.</li>
<li><strong>High sustained bandwidth</strong> is more important than low latency.</li>
</ul>
<h2 id="Interface"><a href="#Interface" class="headerlink" title="Interface"></a>Interface</h2><p>Files are <em>organized hierarchically</em> in directories and <em>identified by pathnames</em>.</p>
<p>support usual operations like <em>create, delete, open, close, read, write</em>.</p>
<p>GFS also has <em>snapshot</em> and <em>record append</em> operations</p>
<ul>
<li><strong>Snapshot</strong> creates a copy of a file or a directory tree at low cost. </li>
<li><strong>Record append</strong> –&gt; atomic append, allows multiple clients to append data to the same file concurrently.</li>
<li>Useful for implementing <strong>multi-way merging</strong> and <strong>producer-consumer queues</strong>.</li>
</ul>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img src="D:\Blog\source_images\image-20221221170828501.png" alt="image-20221221170828501"></p>
<p>GFS Clusters:</p>
<ul>
<li><p>single <em>master</em></p>
</li>
<li><p>multiple <em>chunkserver</em></p>
</li>
<li><p>multiple client (client and chunkserver can be run on same machine)</p>
</li>
<li><p>Each of these is typically a commodity Linux machine running a user-level server process.</p>
</li>
</ul>
<p>File Storage:</p>
<ul>
<li>Files are divided into <strong>fix-sized</strong> chunks.</li>
<li>Each <strong>chunks</strong> identified by an immutable and globally unique 64 bit chunk handle.</li>
<li><strong>Chunk handle</strong> is assigned by the master at the time of chunk creation.</li>
<li>Chunkservers store chunks on local disks as Linux files and read or write chunk data specified by a chunk handle and byte range.</li>
<li>Each chunk is replicated on multiple chunkservers.</li>
</ul>
<p>Single Master:</p>
<ul>
<li>Maintains all filesystem metadata.<ul>
<li>Namespace.</li>
<li>Access control information.</li>
<li>Mapping from file to chunks.</li>
<li>Current location of chunks.</li>
</ul>
</li>
<li>Control system-wide activities.<ul>
<li>Chunk lease management.</li>
<li>Garbage collection of orphaned chunks.</li>
<li>Chunk migration between chunkservers.</li>
</ul>
</li>
<li>Periodically communicate with chunkservers in <em>HeartBeat</em> messages to <em>give it instructions</em> and <em>collect its state</em>.</li>
</ul>
<p>Client:</p>
<ul>
<li>implement the filesystem API.</li>
<li>Communicate with master for metadata and chunkserver for data.</li>
<li>Neither client nor chunkserver cache the data.<ul>
<li>For Client, most app stream through the file, it’s too large to be cached.</li>
<li>it also eliminate cache coherence issues. (<strong>client cache metadata instead</strong>)</li>
<li>For Chunkserver, Linux’s buffer cache is enough.</li>
</ul>
</li>
</ul>
<h3 id="Single-Master"><a href="#Single-Master" class="headerlink" title="Single Master"></a>Single Master</h3><p>Benefit: simplify the design and enable master to make sophisticated chunk replacement and replication decisions by using global knowledge.</p>
<p>But we need to minimize the read and write on master so that it doesn’t become the bottleneck.</p>
<p>So Client only ask master for metadata, and caches this information for a limited time and interacts with the chunkservers directly for many subsequent operations.</p>
<hr>
<p>Simple read operation:</p>
<ol>
<li>Client translates file name and byte offset into chunk index within the file.</li>
<li>Client sends request to master containing chunk index and file name.</li>
<li>Master replies with the corresponding chunk handle and location of replicas.</li>
<li>Client caches the information using the fila name and chunk index as the key.</li>
<li>Client then sends the request to one of the replicas (mostly the closest one), the request specifies the chunk range and chunk handle<ul>
<li>In fact, the client typically asks for multiple chunks in the same request and the master can also include the informa- tion for chunks immediately following those requested</li>
</ul>
</li>
</ol>
<h3 id="Chunk-Size"><a href="#Chunk-Size" class="headerlink" title="Chunk Size"></a>Chunk Size</h3><p>Chunk Size, 64MB, is much larger than file system block sizes.</p>
<p>Each chunk is stored as plain Linux file and extended only as needed. This kind of lazy allocation avoids space wasting due to internal fragmentation.</p>
<p>Advantages of large chunk size:</p>
<ul>
<li>Reduce client’s needs to interact with master.</li>
<li>Since on a large chunk, a client is more likely to perform many operations on a given chunk.</li>
<li>Reduces the size of the metadata stored on the master. Thus we can keep the metadata in memory.</li>
</ul>
<p>Disadvantages of large chunk size:</p>
<ul>
<li>Small files consist a small number of chunks. The chunkservers storing those chunks may become hot spots if many clients are accessing the same file</li>
<li>In practice, hot spot is not a major problem. But hot spots did develop when GFS was first used by a batch-queue system.<ul>
<li>One solution: making the batch-queue system stagger application start times</li>
<li>A potential long-term solution: allow clients to read data from other clients in such situations.</li>
</ul>
</li>
</ul>
<h3 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h3><p>All metadata is kept in memory, there are three kind of metadata:</p>
<ol>
<li>The file and chunk namespace.</li>
<li>The mapping from files to chunks.</li>
<li>location of each chunks’ replicas.</li>
</ol>
<p>First two kinds of metadata (namespaces and file-to-chunk mapping) is logged on local disk and replicated by a remote machine. The master doesn’t store chunk location information, instead, it ask each chunkserver about its chunks at master’s startup and whenever chunkserver joins the cluster.</p>
<hr>
<p>Why we want data structure in-memory?</p>
<ul>
<li>Since metadata is stored in memory, master can easily periodically scan the entire state <strong>in the background</strong>. This periodic scanning is used to implement <strong>chunk garbage collecting</strong>, <strong>re-replication in the presence of chunkserver failures</strong>, <strong>chunk migration between chunkservers for balance-loading and disk space usage</strong>.</li>
</ul>
<p>Why we don’t need to keep chunk location persistent in disk?</p>
<ul>
<li>The master can keep chunk location up-to-date thereafter because it controls all chunk placement and monitors chunkserver status <strong>with regular HeartBeat messages</strong>. This also eliminate the problem of <em>keeping the master and chunkservers in sync</em> as chunkservers <em>join and leave the cluster, change names, fail, restart, and so on</em>.</li>
</ul>
<p>What is operation log?</p>
<ul>
<li>It contains historical record of critical metadata changes.<ul>
<li>It is the only persistent record of metadata.</li>
<li>It serves as local timeline that defines the order of concurrent operations.</li>
<li>Files, chunks and their versions are identified by local time.</li>
</ul>
</li>
<li>Operation log must be stored reliably and we should not make changes visible to clients until metadata changes are made persistent.</li>
<li>We replicate it on multiple remote machines and respond to a client operation only after flushing the corresponding log record to disk both locally and remotely.</li>
<li>The master batches several log records together before flushing thereby reducing the impact of flushing and replication on overall system throughput.</li>
</ul>
<h3 id="Consistency-Model"><a href="#Consistency-Model" class="headerlink" title="Consistency Model"></a>Consistency Model</h3><p>GFS has a relaxed consistency model</p>
<p>What is guarantees by GFS?</p>
<ul>
<li><p><strong>File namespaces mutations are atomic</strong>, it’s handled by master using a namespace locking. And the global total order is defined by master’s operation log file.</p>
</li>
<li><p>File region state after mutation</p>
<ul>
<li>A file region is consistent if all clients will always see the same data, regardless of which replicas they read from.</li>
<li>A region is defined after a file data mutation if it is consistent and clients will see what the mutation writes in its entirety. </li>
<li>When a mutation succeeds without interference from concurrent writers, the affected region is defined.</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>write</th>
<th>record append</th>
</tr>
</thead>
<tbody><tr>
<td>Serial success</td>
<td>defined</td>
<td>defined, interspersed with inconsistent</td>
</tr>
<tr>
<td>Concurrent success</td>
<td>consistent but undefined</td>
<td>defined, interspersed with inconsistent</td>
</tr>
<tr>
<td>Failure</td>
<td>inconsistent</td>
<td>inconsistent</td>
</tr>
</tbody></table>
</li>
<li><p>Atomic append –&gt; data appended <em>at least once</em>, but at an offset of GFS’s choosing.</p>
<ul>
<li>The offset is returned to the client and marks the beginning of a defined region that contains the record.</li>
<li>GFS may insert padding or record duplicates in between.</li>
</ul>
</li>
<li><p>After a sequence of successful mutations, the mutated file region is guaranteed to be defined.</p>
<ul>
<li>By applying mutations to a chunk in same order on all replicas.</li>
<li>By using chunk version to detect stale replica.</li>
<li>Stale chunk will be garbage collected.</li>
</ul>
</li>
<li><p>Client cache the chunk locations, they may read from stale replicas.</p>
<ul>
<li>This window is limited by lease time</li>
<li>stale replica usually return premature end rather than outdated data since most files are append-only.</li>
</ul>
</li>
</ul>
<p>Implication of Applications</p>
<ul>
<li>append-only rather than writes</li>
<li>checkpointing</li>
<li>self-validating, e.g. record checksums</li>
<li>self-identifying, e.g. record identifier</li>
</ul>
<h1 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h1><h2 id="Lease-and-Mutation-Order"><a href="#Lease-and-Mutation-Order" class="headerlink" title="Lease and Mutation Order"></a>Lease and Mutation Order</h2><p>We use lease to maintain a consistent mutation order across replicas. The master grant a chunk lease to one of the replicas, called <em>primary</em>. A <em>primary</em> picks a mutation ordering for all replicas.</p>
<p>Lease mechanism is designed to <strong>minimize management overhead of master</strong>. It has timeout of 60s. </p>
<p><img src="D:\Blog\source_images\image-20221221223610132.png" alt="image-20221221223610132"></p>
<p>Write operation:</p>
<ol>
<li>Client asks Master who is the primary and other replica locations. If there is no primary, master then  grants one</li>
<li>Master replies the information, and client cache the data for future mutations. It needs to request master again only when primary becomes unreachable.</li>
<li>Client pushes data to all replicas. Chunkserver stores the data in local LRU buffer cache until the data is used or aged out.</li>
<li>Once the replicas have acknowledged the data, Client sends write request to primary. The primary assigns consecutive serial numbers to mutations.</li>
<li>The primary forward the write request to all replicas.</li>
<li>The secondary reply to primary when completed.</li>
<li>The primary replies to the client. <ul>
<li>If error happens at the secondary, primary sends error message to client; Then the client request is considered failed, and the modified region is left in an <strong>inconsistent state</strong>.</li>
<li>If it had failed at the primary, it would not have been assigned a serial number and forwarded.</li>
<li>Client code handles such errors by retrying the failed mutation.</li>
</ul>
</li>
</ol>
<p>If a write by the application is large or straddles a chunk boundary, GFS client code breaks it down into multiple write operations. Final result is consistent but maybe undefined because of interleave of other write operations.</p>
<h2 id="Data-Flow"><a href="#Data-Flow" class="headerlink" title="Data Flow"></a>Data Flow</h2><p>The control flow and data flow are decoupled, data is <strong>pushed linearly</strong> along a <strong>carefully picked chain</strong> of chunkservers <strong>in a pipelined fashion</strong> to fully <strong>utilize network bandwidth</strong> (so full outbound bandwidth is used to transfer data as fast as possible).</p>
<p>To <strong>avoid high-latency links</strong>, each machine forward data to “closest” machine in network that has not received the data.</p>
<h2 id="Atomic-Append"><a href="#Atomic-Append" class="headerlink" title="Atomic Append"></a>Atomic Append</h2><p>Difference between traditional write and record append?</p>
<ul>
<li>Traditional write: Client specify data and offset –&gt; the concurrent write is not serializable.</li>
<li>In record append (atomic append), Client only specify the data, GFS determine the offset and appends data to the file at least once atomically. And GFS returns the offset to the client.</li>
</ul>
<p>Why we need atomic append?</p>
<ul>
<li>Without atomic append, Clients would need more complicated and expensive synchronization, like through a lock manager.</li>
</ul>
<p>How does atomic append do?</p>
<ul>
<li><p>Record append is mutation that follows the control flow above with only a little extra logic at the primary. </p>
<ul>
<li><p>The primary checks to see if appending the record to the current chunk would cause the chunk to exceed the maximum size (64 MB). If so, it pads the chunk to the maximum size, tells secondaries to do the same, and replies to the client indicating that the operation should be retried on the next chunk.</p>
</li>
<li><p>Record append is restricted to be at most one-fourth of the maximum chunk size to keep worstcase fragmentation at an acceptable level.</p>
</li>
</ul>
</li>
</ul>
<p>How to deal with the inconsistency caused by atomic append?</p>
<ul>
<li>If a record append fails at any replica, the client retries the operation. </li>
<li>As a result, replicas of the same chunk may contain different data possibly including duplicates of the same record in whole or in part. GFS does not guarantee that all replicas are bytewise identical.</li>
<li>Record is written <em><strong>at least once</strong></em>!</li>
<li>Application is responsible for dealing with the inconsistency.</li>
</ul>
<h2 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h2><p>How to implement snapshot using a <strong>copy-on-write</strong> technique?</p>
<ol>
<li>Master receive a snapshot request and then revoke leases.</li>
<li>Master log the request to disk. Then create new files but pointing to same chunks as source files.</li>
<li>When Client want to write to chunk C in new files, It sends request to master to find lease holder, The Master noticed that the reference to C is greater than 1, It then asks each chunkserver that has a current replica of C to create a new chunk called C’. <ul>
<li>By creating the new chunk on the same chunkservers as the original, we ensure that the data can be copied locally, not over the network.</li>
</ul>
</li>
</ol>
<h1 id="Master-Operation"><a href="#Master-Operation" class="headerlink" title="Master Operation"></a>Master Operation</h1><p>Master manage namespace operations, manage chunk replicas throughout the system, make placement decisions, create new chunks, coordinate system-wide activities, balance load.</p>
<h2 id="Namespace-Management-and-Locking"><a href="#Namespace-Management-and-Locking" class="headerlink" title="Namespace Management and Locking"></a>Namespace Management and Locking</h2><p>Unlike traditional filesystems, GFS logically represent its namespace as lookup table mapping pathname to metadata. </p>
<p>Prefix compression –&gt; makes it suitable in memory. </p>
<p>Each node in lookup table has a read-write lock. </p>
<p>How to lock?</p>
<ul>
<li>Since the namespace can have many nodes, read-write lock objects are allocated lazily and deleted once they are not in use.</li>
<li>locks are acquired in a consistent total order to prevent deadlock: they are first ordered by level in the namespace tree and lexicographically within the same level.</li>
</ul>
<h2 id="Replica-Placement-Physically"><a href="#Replica-Placement-Physically" class="headerlink" title="Replica Placement (Physically)"></a>Replica Placement (Physically)</h2><p>Purpose of chunk replica placement policy:</p>
<ul>
<li>maximize data reliability and availability</li>
<li>maximize network bandwidth utilization</li>
</ul>
<p>Method: Spread chunk replicas across racks. This ensures that some replicas of a chunk will survive and remain available even if an entire rack is damaged or offline (such as network partitioning).</p>
<h2 id="Replicas-Management"><a href="#Replicas-Management" class="headerlink" title="Replicas Management"></a>Replicas Management</h2><p>Chunk replicas are created for three reasons: </p>
<ul>
<li>chunk creation</li>
<li>re-replication</li>
<li>rebalancing.</li>
</ul>
<p>Where to place initial empty replicas when creating a chunk?</p>
<ul>
<li>We want to place new replicas on chunkserver whose spare disk space is more than average.</li>
<li>We want to limit recent creation on chunkserver (to avoid heavy write on this chunkserver)</li>
<li>We want to spread chunk replicas across racks.</li>
</ul>
<p>The master re-replicates a chunk as soon as the number of available replicas falls below a user-specified goal. Similar to creating a chunk replica.</p>
<p>The master rebalances replicas periodically: it examines the current replica distribution and moves replicas for better disk space and load balancing.</p>
<h2 id="Garbage-Collection"><a href="#Garbage-Collection" class="headerlink" title="Garbage Collection"></a>Garbage Collection</h2><p>After a file is deleted, GFS does not immediately reclaim the available physical storage. It does so only lazily during regular garbage collection at both the file and chunk levels</p>
<p>How GFS do garbage collection?</p>
<ul>
<li><p>For Master</p>
<ul>
<li><p>When a file is deleted, it is logged by master immediately. But master rename it to a hidden name with  deletion timestamp.</p>
</li>
<li><p>During the master’s regular scan of the file system namespace, it removes any such hidden files if they have existed for more than three days.</p>
</li>
</ul>
</li>
<li><p>For Chunkserver</p>
<ul>
<li>In a similar regular scan of the chunk namespace, the master identifies orphaned chunks and erases the metadata for those chunks. </li>
<li>In a HeartBeat message regularly exchanged with the master, each chunkserver reports a subset of the chunks it has, and the master replies with the identity of all chunks that are no longer present in the master’s metadata. </li>
<li>Then the chunkserver is free to delete its replicas of such chunks.</li>
</ul>
</li>
</ul>
<p>Benefit:</p>
<ol>
<li>Simple and reliable for distributed system.</li>
<li>It merge storage reclamation into regular background activities.</li>
<li>The delay in reclaiming storage provides a safety net against accidental, irreversible deletion.</li>
</ol>
<p>Main disadvantage: frequently creation and deletion will cause the space tight.</p>
<p>Solution: expediting storage reclamation if a deleted file is explicitly deleted again.</p>
<h2 id="Stale-Replica-Detection"><a href="#Stale-Replica-Detection" class="headerlink" title="Stale Replica Detection"></a>Stale Replica Detection</h2><p>Master increase the chunk version number when it grant a new lease on a chunk. When a replica is not available at this time, its chunk version will not advanced. So when it restart and report its chunk version number to Master, Master will detect that it is a stale replica. </p>
<p>The master removes stale replicas in its regular garbage collection </p>
<h1 id="Fault-Tolerance"><a href="#Fault-Tolerance" class="headerlink" title="Fault Tolerance"></a>Fault Tolerance</h1><p>Two problems caused by <strong>component failure</strong>:</p>
<ul>
<li>unavailability</li>
<li>corrupted data</li>
</ul>
<h2 id="Availability"><a href="#Availability" class="headerlink" title="Availability"></a>Availability</h2><p>Two strategies for high availability:</p>
<ul>
<li>Fast Recovery<ul>
<li>Restore state and restart no matter how they terminated.</li>
</ul>
</li>
<li>Replication<ul>
<li>Chunk Replication</li>
<li>Master Replication</li>
</ul>
</li>
</ul>
<h2 id="Data-Integrity"><a href="#Data-Integrity" class="headerlink" title="Data Integrity"></a>Data Integrity</h2><p>Why we need checksum in chunkserver to detect corruption of stored data?</p>
<ul>
<li>Disks and machines failures are common, causing data corruption.</li>
<li>But it’s impractical to compare replicas to detect corruption. Besides, the semantic of record append doesn’t guarantee identical replicas.</li>
<li>Therefore, each chunkserver must independently verify the integrity of its own copy by maintaining checksums.</li>
</ul>
<p>What happens when reading corrupted data?</p>
<ul>
<li>For Reads, chunkserver verify checksum of data block before returning any data to requester.</li>
<li>If it doesn’t match the checksum, it returns a error to requester and report a mismatch to the master.</li>
<li>Master re-replicate the chunk.</li>
<li>Then master instruct deletion of the corrupted replica.</li>
</ul>
<p>How to calculate checksum when writing data?</p>
<ul>
<li>For appending, There is no need to read the data to checksum first. Because we can checksum later when reading this data.</li>
<li>For random writing, we must read the data and checksum first.</li>
</ul>
<p>Like other metadata, checksums are kept in memory and stored persistently with logging, separate from user data.</p>
<p>During idle periods, chunkservers can scan and verify the contents of inactive chunks.</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>GFS structure:</p>
<ul>
<li>Master Data: two tables that matter<ul>
<li>file name –&gt; array of chunk handles</li>
<li>handle –&gt; list of chunk servers, version number, primary, lease expiration</li>
<li>Log and Checkpoint of the 2 above tables –&gt; disk</li>
</ul>
</li>
</ul>
<p>GFS read operation:</p>
<ol>
<li>Client sends file and offset to Master.</li>
<li>Master sends back chunk handles and list of servers back to Client.<ul>
<li>Client cache the map.</li>
</ul>
</li>
<li>Client talk to one of the chunk servers (maybe one closest to the Client)<ul>
<li>chunk server runs Linux filesystem, chunk is stored by file whose name is chunk handle.</li>
</ul>
</li>
<li>Chunk server sends back the chunk files to Client.</li>
</ol>
<p>GFS write(append) operation:</p>
<ul>
<li><p>No Primary</p>
<ol>
<li>Find up-to-date replicas (according to the version numbers in the master).</li>
<li>Pick a primary and a secondary.</li>
<li>Increase the version number.</li>
<li>Sends the primary and secondary with the updated version number and messages and <em>lease</em>.</li>
<li>Master write the version number to the disk.</li>
</ol>
</li>
<li><p>Primary</p>
<ol>
<li>Client sends message to Primary.</li>
<li>Primary sends message to Secondary.</li>
<li>If all Secondary replies ok, Primary sends ok to Client.</li>
<li>Else Primary sends not ok to Client.</li>
</ol>
</li>
</ul>
<p>why we need lease?</p>
<ul>
<li>to avoid “split brain” problem caused by network partition</li>
</ul>
]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title>Go Network</title>
    <url>/2022/12/16/Go-Network/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>Network</tag>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>Current Limit</title>
    <url>/2022/12/15/Current-Limit/</url>
    <content><![CDATA[]]></content>
      <tags>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title>MapReduce</title>
    <url>/2022/12/15/MapReduce/</url>
    <content><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>MapReduce: a <strong>programming model</strong> and <strong>associated implementation</strong> for <strong>processing and generating large datasets</strong>.</p>
<ul>
<li>Map: process key&#x2F;value pair to generate intermediate key&#x2F;value pairs.</li>
<li>Reduce: merges all intermediate values associated with the same intermediate key.</li>
</ul>
<span id="more"></span>

<p>runtime system responsibility:</p>
<ul>
<li>Partitioning the input data.</li>
<li>Scheduling the program’s execution across a set of machines.</li>
<li>Handling managed failures.</li>
<li>Managing inter-machine communication.</li>
</ul>
<p>Motivation:</p>
<ul>
<li>Special purpose coding on distributed systems is hard.</li>
<li>Hide the messy details of parallelization, fault-tolerance, data distribution and load balancing.</li>
</ul>
<h1 id="Programming-Model"><a href="#Programming-Model" class="headerlink" title="Programming Model"></a>Programming Model</h1><h2 id="Types"><a href="#Types" class="headerlink" title="Types"></a>Types</h2><p>map and reduce functions are deterministic functions: always get the same output with same input.</p>
<p>map: (k1, v1) –&gt; list(k2, v2)</p>
<p>reduce: (k2, list(v2)) –&gt; list(v3)</p>
<p>Input keys and values are drawn from different domain than the output keys and values. But intermediate keys and values are from the same domain. </p>
<h2 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h2><ul>
<li><p>Distributed Grep</p>
</li>
<li><p>Count of URL Access Frequency</p>
</li>
<li><p>Reverse Web-Link Graph: The map function outputs $&lt;target, source&gt;$ pairs for each link to a target URL found in a page named source. The reduce function concatenates the list of all source URLs associated with a given target URL and emits the pair $&lt;target, list(source)&gt;$</p>
</li>
<li><p>Term-Vector per Host</p>
</li>
<li><p>Inverted Index: The map function parses each document, and emits a sequence of $&lt;word, document ID&gt;$ pairs. The reduce function accepts all pairs for a given word, sorts the corresponding document IDs and emits a $&lt;word, list(document ID)&gt;$ pair. The set of all output pairs forms a simple inverted index. It is easy to augment this computation to keep track of word positions.</p>
</li>
<li><p>Distributed Sort: The map function extracts the key from each record, and emits a $&lt;key, record&gt;$ pair. The reduce function emits all pairs unchanged. This computation depends on the partitioning functions and the R files’ ordering properties.</p>
</li>
</ul>
<h1 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h1><p>Implementation environment:</p>
<ul>
<li>Commodity computers are used.</li>
<li>Network (switched Ethernet) is the bottleneck.</li>
<li>Cluster of computers, thus <strong>machine failures are common</strong>.</li>
<li>Storage hardware is inexpensive; using a distributed file system (GFS) to manage data; replication is used.</li>
<li>Users submit jobs to a scheduling system. Each <strong>job</strong> consists of <strong>a set of tasks</strong>, and is <strong>mapped by the scheduler</strong> to a set of available machines within a cluster.</li>
</ul>
<h2 id="Execution-Overview"><a href="#Execution-Overview" class="headerlink" title="Execution Overview"></a>Execution Overview</h2><p><img src="D:\Blog\source_images\image-20221217145110248.png" alt="image-20221217145110248"></p>
<p>What happens when user call MapReduce:</p>
<ol>
<li>The MapReduce library first split input files into M pieces of typically 16 to 64 MB per pieces. It then starts up many copies of the user program on a cluster of machines.</li>
<li>The copied program on master is special. The rest are workers that are assigned work by the master. There are M map tasks and R reduce tasks to assign. The master picks idle workers and assigns each one a map task or a reduce task.</li>
<li>A worker who is assigned a map task reads the input split, and use user-defined map function to process the split. The <strong>intermediate keys and values are buffered in the memory</strong>.</li>
<li><strong>Periodically, the buffered pairs are written to disk</strong>, partitioned into R regions by partition function i.e. $hash(key)%R$. The locations of these buffered pairs on the local disk are passed back to the master, who is responsible for forwarding these locations to the reduce workers.</li>
<li>When a reducer worker is notified by master about the locations, it then uses remote procedure call (RPC) to remotely reads the intermediate keys and values from the map worker’s local disks.</li>
<li>When a reduce worker has read all intermediate data, it sorts it by the intermediate keys so that all occurrences of the same key are grouped together. The <em><strong>sorting is needed because typically many different keys map to the same reduce task</strong></em>. If the amount of intermediate data is too large to fit in memory, an <strong>external sort</strong> (i.e. external merge sort) is used.</li>
<li>The reduce worker iterate the sorted intermediate data, for each unique intermediate key encountered, it passed the key and the corresponding list of intermediate values to user’s reduce function. The output of Reduce function is appended to a final output file for this reduce partition.</li>
<li>When all map tasks and reduce tasks had been done, the master wakeup the user program.</li>
<li>After successful completion, the output is available in R output files. They can be used as input of another MapReduce call.</li>
</ol>
<h2 id="Master-Data-Structures"><a href="#Master-Data-Structures" class="headerlink" title="Master Data Structures"></a>Master Data Structures</h2><p>For each map task and reduce task, it stores:</p>
<ul>
<li>The state (idle, in-progress, or completed)</li>
<li>The identity of the worker machine (for non-idle tasks).</li>
</ul>
<p>master is like a conduit:</p>
<ul>
<li>it propagate the location of R regions on map tasks to reduce tasks</li>
<li>Therefore, for each completed map tasks, the master stores the locations and sizes of R regions.</li>
<li>Updates to this location and size information are received as map tasks are completed. The information is pushed incrementally to workers that have in-progress reduce tasks</li>
</ul>
<h2 id="Fault-Tolerance"><a href="#Fault-Tolerance" class="headerlink" title="Fault Tolerance"></a>Fault Tolerance</h2><h3 id="Worker-Failure"><a href="#Worker-Failure" class="headerlink" title="Worker Failure"></a>Worker Failure</h3><p>How to determine failure of worker?</p>
<ul>
<li>The master pings every worker periodically. If no response is received from a worker in a certain amount of time, the master marks the worker as failed.</li>
</ul>
<p>Which tasks to rollback when workers failed?</p>
<ul>
<li>Any map tasks completed by the failed worker are reset back to their initial idle state, and therefore become eligible for scheduling on other workers. </li>
<li>Similarly, any map task or reduce task in progress on a failed (map or reduce separately) worker is also reset to idle and becomes eligible for rescheduling.</li>
</ul>
<p> Why completed map tasks on failed worker should re-execute while completed reduce tasks don’t?</p>
<ul>
<li>Completed map tasks are re-executed on a failure because their <em>output is stored on the local disk(s)</em> of the failed machine and is therefore <strong>inaccessible</strong>. </li>
<li>Completed reduce tasks do not need to be re-executed since <strong>their output is stored in a global file system</strong>.</li>
</ul>
<p>What happens if map tasks are re-executed?</p>
<ul>
<li>When a map task is executed first by worker A and then later executed by worker B (because A failed), all workers executing reduce tasks are notified of the re-execution. Any reduce task that has not already read the data from worker A will read the data from worker B.</li>
</ul>
<h3 id="Master-Failure"><a href="#Master-Failure" class="headerlink" title="Master Failure"></a>Master Failure</h3><p>Can be solved with periodic checkpoints of master data structure.</p>
<p>But since there is only one master, it’s unlikely to fail.</p>
<p>So when master fails, we can just abort the computation.</p>
<h3 id="Semantics"><a href="#Semantics" class="headerlink" title="Semantics"></a>Semantics</h3><p>When user-supplied map and reduce functions are deterministic:</p>
<ul>
<li>MapReduce will produce the same output as non-faulting sequential execution of program.</li>
<li>That property relies on <em><strong>atomic commit</strong></em> of map and reduce tasks.<ul>
<li>For map tasks: when a map task completes, the worker sends a message to the master and includes the names of the R temporary files in the message. <em>If the master receives a completion message for an already completed map task, it ignores the message. Otherwise, it records the names of R files in a master data structure</em>.</li>
<li>For reduce tasks: when a reduce task completes, the <em>reduce worker atomically renames its temporary output file to the final output file</em>. If the same reduce task is executed on multiple machines, multiple rename calls will be executed for the same final output file. We rely on the atomic rename operation provided by the underlying file system to guarantee that the final file system state contains just the data produced by one execution of the reduce task.</li>
</ul>
</li>
</ul>
<p>When user-supplied map and reduce functions are non-deterministic:</p>
<ul>
<li>MapReduce will provide weaker but still reasonable semantics.</li>
<li>In the presence of non-deterministic operators, the output of a particular reduce task R1 is equivalent to the output for R1 produced by a sequential execution of the non-deterministic program. However, the output for a different reduce task R2 may correspond to the output for R2 produced by a different sequential execution of the non-deterministic program.</li>
<li>Consider map task M and reduce tasks $R_1$ and $R_2$. Let $e(R_i)$ be the execution of $R_i$ that committed (there is exactly one such execution). The weaker semantics arise because $e(R_1)$ may have read the output produced by one execution of M and $e(R_2)$ may have read the output produced by a different execution of M.</li>
</ul>
<h2 id="Locality"><a href="#Locality" class="headerlink" title="Locality"></a>Locality</h2><p>Since network bandwidth is the bottleneck, one optimization is that running GFS and MapReduce on the same set of machines. And master schedule map tasks to read input locally as possible.</p>
<h2 id="Task-Granularity"><a href="#Task-Granularity" class="headerlink" title="Task Granularity"></a>Task Granularity</h2><p>Ideally M and R should be much larger than number of workers</p>
<ul>
<li>Improves load balancing</li>
<li>Speeds up recovery</li>
</ul>
<p>Practical bounds of M and R:</p>
<ul>
<li>master must take $O(M+R)$ to do scheduling, and take $O(M*R)$ piece of state.</li>
<li>R is also constrained by users because the output of each reduce task ends up in a separate output file.</li>
<li>R is often a small multiple of the number of worker machines we expect to use.</li>
</ul>
<h2 id="Backup-Tasks"><a href="#Backup-Tasks" class="headerlink" title="Backup Tasks"></a>Backup Tasks</h2><p>What is a straggler?</p>
<ul>
<li>straggler is the machine that takes an unusually long time to compute the tasks, it’s often the bottleneck.</li>
</ul>
<p> Backup mechanism to deal with straggler</p>
<ul>
<li>When a <strong>MapReduce operation is close to completion</strong>, the master <strong>schedules backup executions of the remaining in-progress tasks</strong>.</li>
<li>The task is marked as completed whenever either the primary or the backup execution completes.</li>
</ul>
<h1 id="Refinement"><a href="#Refinement" class="headerlink" title="Refinement"></a>Refinement</h1><h2 id="Partition-Function"><a href="#Partition-Function" class="headerlink" title="Partition Function"></a>Partition Function</h2><p>Default partition function: $hash(key)%R$, this tends to generate well-balanced partitions.</p>
<p>But sometimes input are skewed, we need some special partition functions.</p>
<p>For example, when output keys are URLs, and we want all entries for a single host to end up in the same output file. We can then use $hash(Hostname(url))$.</p>
<h2 id="Ordering-Guarantees"><a href="#Ordering-Guarantees" class="headerlink" title="Ordering Guarantees"></a>Ordering Guarantees</h2><p>Within a given partition, the intermediate key&#x2F;value pairs are processed in increasing key order (because it is sorted by reduce). </p>
<p>This ordering makes it easy to <em><strong>generate a sorted output file per partition</strong></em>, which is useful when the output file format needs to support efficient <strong>random access lookups by key</strong> (hash + binary search, similar to hash join algorithm in database)</p>
<h2 id="Combiner-Functions"><a href="#Combiner-Functions" class="headerlink" title="Combiner Functions"></a>Combiner Functions</h2><p>Combiner functions is like a reduce function but runs on map workers.</p>
<p>It can reduce the network overhead by pre-processing (aggregating) the keys and values.</p>
<p>For some kind of tasks, it’s very useful.</p>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><h3 id="Input-and-Output-Formats"><a href="#Input-and-Output-Formats" class="headerlink" title="Input and Output Formats"></a>Input and Output Formats</h3><p>Text mode: treat each line as key&#x2F;value pair</p>
<ul>
<li>key: offset in the file</li>
<li>value: content of the line</li>
</ul>
<p>Reader mode: user provide reader interface to split the range.</p>
<h3 id="Side-effects"><a href="#Side-effects" class="headerlink" title="Side effects"></a>Side effects</h3><p>It is useful to generate auxiliary files in map or reduce tasks, MapReduce don’t provide two-phase commit. Therefore, tasks that produce multiple output files with cross-file consistency requirements should be deterministic.</p>
<h3 id="Skipping-Bad-Records"><a href="#Skipping-Bad-Records" class="headerlink" title="Skipping Bad Records"></a>Skipping Bad Records</h3><p>Sometimes it is feasible to ignore some bad records caused by user program, for example doing a statistic analysis on a large dataset.</p>
<p>MapReduce provide some mode to detect records that caused deterministic crashes and skip these records.</p>
<h3 id="Local-Execution"><a href="#Local-Execution" class="headerlink" title="Local Execution"></a>Local Execution</h3><p>Debugging MapReduce is triky, so MapReduce provide tools of debugging, profiling, and small-scale testing, enabling sequentially execute all of the work for a MapReduce operation on the local machine.  </p>
<h3 id="Status-Information"><a href="#Status-Information" class="headerlink" title="Status Information"></a>Status Information</h3><p>The master runs an internal HTTP server and exports a set of status pages for human consumption. </p>
<h3 id="Counters"><a href="#Counters" class="headerlink" title="Counters"></a>Counters</h3><p>The MapReduce library provides a counter facility to count occurrences of various events. </p>
<p>To use this facility, <em>user code creates a named counter object</em> and then <em>increments the counter appropriately in the Map and&#x2F;or Reduce function</em>. For example:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Counter *uppercase;</span><br><span class="line">uppercase = <span class="built_in">GetCounter</span>(<span class="string">&quot;uppercase&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">map</span>(String name, String contents) &#123;</span><br><span class="line">    <span class="keyword">for</span> (w : contents) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">isCapitalized</span>(w)) &#123;</span><br><span class="line">            uppercase-&gt;<span class="built_in">Increment</span>()</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">EmitIntermediate</span>(w, <span class="string">&quot;1&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>The counter values from individual worker machines are periodically propagated to the master (<em>piggybacked</em> on the ping response). </p>
<p>The master aggregates the counter values from successful map and reduce tasks and returns them to the user code when the MapReduce operation is completed. </p>
<p>The current counter values are also displayed on the master status page so that a human can watch the progress of the live computation. </p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>Success of MapReduce</p>
<ol>
<li>Model is easy to use, it hides parallelism, load balance, locality, fault tolerance, etc.</li>
<li>Model is expressive, can be used to solve many problems.</li>
<li>It has scalability, fault tolerance, consistency.</li>
</ol>
<p>Some takeaways</p>
<ol>
<li>Restricting programming model makes it easy for parallelism and fault tolerance.</li>
<li>Network bandwidth is scarce resource. (locality optimization).</li>
<li>Redundant execution can be used to reduce the impact of slow machines.</li>
</ol>
]]></content>
      <tags>
        <tag>Distributed System</tag>
      </tags>
  </entry>
  <entry>
    <title>Go Concurrency</title>
    <url>/2022/12/15/Go-Concurrency/</url>
    <content><![CDATA[<blockquote>
<p>Materials:</p>
<ul>
<li><a href="https://vimeo.com/49718712">concurrency is not parallelism</a></li>
<li><a href="https://drive.google.com/file/d/1nPdvhB0PutEJzdCq5ms6UI58dp50fcAN/view">rethinking classical concurrency patterns</a></li>
<li><a href="https://pkg.go.dev/sync#pkg-overview">go sync package</a></li>
<li><a href="https://go.dev/talks/2012/concurrency.slide#1">go concurrency patterns</a></li>
<li><a href="https://blogtitle.github.io/categories/concurrency/">go advanced concurrency patterns</a></li>
</ul>
</blockquote>
<span id="more"></span>

<h1 id="Concurrency-Overview"><a href="#Concurrency-Overview" class="headerlink" title="Concurrency Overview"></a>Concurrency Overview</h1><p>Why concurrency?</p>
<ul>
<li>I&#x2F;O concurrency (network capacity, disk capacity)</li>
<li>Parallelism (multi-core machine)</li>
<li>Convenience (periodic work)</li>
</ul>
<p>Distinctions between concurrency and parallelism?</p>
<ul>
<li>Parallelism: simultaneous executing of programs, which may be correlated, or not be.</li>
<li>Concurrency:  composition of independent executing programs. <em>it’s not same as parallelism, although it enables parallelism</em>!</li>
</ul>
<p>Essence of concurrency:</p>
<ul>
<li>A complex problem can be broken down into several easy-to-understand components.</li>
<li>The pieces can be composed concurrently.</li>
<li>The result is <strong>scalable, correct and maybe parallel</strong>.</li>
</ul>
<h1 id="Go-Concurrency-Features"><a href="#Go-Concurrency-Features" class="headerlink" title="Go Concurrency Features"></a>Go Concurrency Features</h1><h2 id="Goroutines"><a href="#Goroutines" class="headerlink" title="Goroutines"></a>Goroutines</h2><p>Goroutines</p>
<ul>
<li>It’s independently executing program with its own stack which can shrink and grow automatically</li>
<li>Goroutines are multiplexed dynamically onto threads as needed</li>
</ul>
<h2 id="Channels"><a href="#Channels" class="headerlink" title="Channels"></a>Channels</h2><p>Communicating in go?</p>
<ul>
<li>Communicating in golang is through channels, it’s more like via file descriptor;</li>
<li>While in original CSP (Communicating Sequential Processing) is through process name, it’s more like via file</li>
</ul>
<p>Synchronization and Communication:</p>
<ul>
<li>Both send and receive are synchronous</li>
<li>A sender and receiver must both be ready to play their part in the communication. Otherwise we wait until they are.</li>
<li>Thus <strong>channels both communicate and synchronize</strong>.</li>
</ul>
<h2 id="Buffered-Channels"><a href="#Buffered-Channels" class="headerlink" title="Buffered Channels"></a>Buffered Channels</h2><p>Buffered channels remove synchronization</p>
<p>It seems like Erlang’s mailbox</p>
<h2 id="The-Go-Approach"><a href="#The-Go-Approach" class="headerlink" title="The Go Approach"></a>The Go Approach</h2><p>Principle: <strong>Don’t communicate by sharing memory (i.e. mutex, locks), share memory by communicating.</strong></p>
<p>Low level concurrency: lock, mutex, condition, waitgroup, pool.</p>
<p>high level concurrency: goroutine, channel.</p>
<p><strong>garbage collector, closure, channel, goroutine, select</strong> – these features just stitch together to make concurrency in go powerful and expressive.</p>
<h1 id="Go-Concurrency-Patterns"><a href="#Go-Concurrency-Patterns" class="headerlink" title="Go Concurrency Patterns"></a>Go Concurrency Patterns</h1><h2 id="Generator-Function-Returns-a-Channel"><a href="#Generator-Function-Returns-a-Channel" class="headerlink" title="Generator : Function Returns a Channel"></a>Generator : Function Returns a Channel</h2><h3 id="Normal-Generator-Model"><a href="#Normal-Generator-Model" class="headerlink" title="Normal Generator Model"></a>Normal Generator Model</h3><p>Channels are first-class values (so as functions).</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">c := boring(<span class="string">&quot;boring!&quot;</span>) <span class="comment">// Function returning a channel.</span></span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">    fmt.Printf(<span class="string">&quot;You say: %q\n&quot;</span>, &lt;-c)</span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(<span class="string">&quot;You&#x27;re boring; I&#x27;m leaving.&quot;</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">boring</span><span class="params">(msg <span class="type">string</span>)</span></span> &lt;-<span class="keyword">chan</span> <span class="type">string</span> &#123; <span class="comment">// Returns receive-only channel of strings.</span></span><br><span class="line">    c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">string</span>)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; <span class="comment">// We launch the goroutine from inside the function.</span></span><br><span class="line">        <span class="keyword">for</span> i := <span class="number">0</span>; ; i++ &#123;</span><br><span class="line">            c &lt;- fmt.Sprintf(<span class="string">&quot;%s %d&quot;</span>, msg, i)</span><br><span class="line">            time.Sleep(time.Duration(rand.Intn(<span class="number">1e3</span>)) * time.Millisecond)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line">    <span class="keyword">return</span> c <span class="comment">// Return the channel to the caller.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Channels-as-a-Handle-on-a-Service"><a href="#Channels-as-a-Handle-on-a-Service" class="headerlink" title="Channels as a Handle on a Service"></a>Channels as a Handle on a Service</h3><p>Our boring function above returns a channel that lets us communicate with the boring service it provides.</p>
<p>We can have more instances of the service.</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    joe := boring(<span class="string">&quot;Joe&quot;</span>)</span><br><span class="line">    ann := boring(<span class="string">&quot;Ann&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">        fmt.Println(&lt;-joe)</span><br><span class="line">        fmt.Println(&lt;-ann)</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Println(<span class="string">&quot;You&#x27;re both boring; I&#x27;m leaving.&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Multiplexing-Fan-In"><a href="#Multiplexing-Fan-In" class="headerlink" title="Multiplexing (Fan-In)"></a>Multiplexing (Fan-In)</h3><p>These programs make Joe and Ann count in lockstep.  </p>
<p>We can instead use a fan-in function to let whosoever is ready talk.</p>
<p>It uses multi-channels as input and output a channel that receive multi channels’ output in different goroutines.</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">fanIn</span><span class="params">(input1, input2 &lt;-<span class="keyword">chan</span> <span class="type">string</span>)</span></span> &lt;-<span class="keyword">chan</span> <span class="type">string</span> &#123;</span><br><span class="line">    c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">string</span>)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; <span class="keyword">for</span> &#123; c &lt;- &lt;-input1 &#125; &#125;()</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; <span class="keyword">for</span> &#123; c &lt;- &lt;-input2 &#125; &#125;()</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    c := fanIn(boring(<span class="string">&quot;Joe&quot;</span>), boring(<span class="string">&quot;Ann&quot;</span>))</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10</span>; i++ &#123;</span><br><span class="line">        fmt.Println(&lt;-c)</span><br><span class="line">    &#125;</span><br><span class="line">    fmt.Println(<span class="string">&quot;You&#x27;re both boring; I&#x27;m leaving.&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph LR</span><br><span class="line">input1 --&gt; channel1 --&gt; channel3</span><br><span class="line">input2 --&gt; channel2 --&gt; channel3</span><br><span class="line">channel3 --&gt; output</span><br></pre></td></tr></table></figure>

<h3 id="Restoring-Sequencing"><a href="#Restoring-Sequencing" class="headerlink" title="Restoring Sequencing"></a>Restoring Sequencing</h3><p>Fan-In is useful, but sometimes we want restoring the sequencing of two services.</p>
<p>Idea is <strong>sending a channel on a channel, making goroutines wait its turn</strong></p>
<p>So, first we define a struct that contains a channel for the reply</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Message <span class="keyword">struct</span> &#123;</span><br><span class="line">    str <span class="type">string</span></span><br><span class="line">    wait <span class="keyword">chan</span> <span class="type">bool</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>For receiver who receives message:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">    msg1 := &lt;-c</span><br><span class="line">    fmt.Println(msg1)</span><br><span class="line">    msg2 := &lt;-c</span><br><span class="line">    fmt.Println(msg2)</span><br><span class="line">    msg1.wait &lt;- <span class="literal">true</span>	<span class="comment">// unlock the sender which is stalled on &lt;-WaitForIt</span></span><br><span class="line">    msg2.wait &lt;- <span class="literal">true</span>	<span class="comment">// unlock the sender which is stalled on &lt;-WaitForIt</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>For Sender who sends message:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">WaitForIt := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">bool</span>)</span><br><span class="line"><span class="keyword">for</span> ExistUnsentMessage() &#123;</span><br><span class="line">    c &lt;- message&#123;<span class="string">&quot;message&quot;</span>, WaitForIt&#125;</span><br><span class="line">    time.Sleep(time.Duration(rand.Intn(<span class="number">2e3</span>)) * time.Millisecond)</span><br><span class="line">    &lt;-WaitForIt		<span class="comment">// get stalled when </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>The technique above can restore the sequence of message: for the fact that Sender cannot send message twice to channel <code>c</code> because it will get stalled in <code>&lt;-WaitForIt</code> statement</p>
<blockquote>
<p>Assume sender1 sends on msg1, then it will get stalled on <code>&lt;-WaitForIt</code>, sender2 then can send on msg2, and also get stalled on <code>&lt;-WaitForIt</code>, and because sender1 sent first, so sender1 get stalled on <code>c &lt;- message&#123;...&#125;</code> first, so msg1 is still sender1</p>
</blockquote>
<blockquote>
<p> Assume sender1 sends on msg2, then sender2 sends on msg1, so the same situation as above  </p>
</blockquote>
<h2 id="Select-Statement"><a href="#Select-Statement" class="headerlink" title="Select Statement"></a>Select Statement</h2><h3 id="Fan-In-Using-Select"><a href="#Fan-In-Using-Select" class="headerlink" title="Fan-In Using Select"></a>Fan-In Using Select</h3><p>By using select statement, we only need to start one goroutine to fan-in channels.</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">fanIn</span><span class="params">(input1, input2 &lt;-<span class="keyword">chan</span> <span class="type">string</span>)</span></span> &lt;-<span class="keyword">chan</span> <span class="type">string</span> &#123;</span><br><span class="line">    c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">string</span>)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">for</span> &#123;</span><br><span class="line">            <span class="keyword">select</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> s := &lt;-input1:  c &lt;- s</span><br><span class="line">            <span class="keyword">case</span> s := &lt;-input2:  c &lt;- s</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Timeout-Using-Select"><a href="#Timeout-Using-Select" class="headerlink" title="Timeout Using Select"></a>Timeout Using Select</h3><p>The time.After function returns a channel that blocks for the specified duration.<br>After the interval, the channel delivers the current time, once.</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    c := boring(<span class="string">&quot;Joe&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">        <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> s := &lt;-c:</span><br><span class="line">            fmt.Println(s)</span><br><span class="line">        <span class="keyword">case</span> &lt;-time.After(<span class="number">1</span> * time.Second):</span><br><span class="line">            fmt.Println(<span class="string">&quot;You&#x27;re too slow.&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Timeout-for-Whole-Conversation-Using-Select"><a href="#Timeout-for-Whole-Conversation-Using-Select" class="headerlink" title="Timeout for Whole Conversation Using Select"></a>Timeout for Whole Conversation Using Select</h3><p>Create the timer once, outside the loop, to time out the entire conversation.<br>While in the previous program, we had a timeout for each message.</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    c := boring(<span class="string">&quot;Joe&quot;</span>)</span><br><span class="line">    timeout := time.After(<span class="number">5</span> * time.Second)</span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">        <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> s := &lt;-c:</span><br><span class="line">            fmt.Println(s)</span><br><span class="line">        <span class="keyword">case</span> &lt;-timeout:</span><br><span class="line">            fmt.Println(<span class="string">&quot;You talk too much.&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Receive-on-quit-channel"><a href="#Receive-on-quit-channel" class="headerlink" title="Receive on quit channel"></a>Receive on quit channel</h3><p>When it want to quit a goroutine, send message on quit channel</p>
<p><code>case &lt;-quit</code> will do cleanup (like remove a temporary file), and tell back that it had quit (<strong>round-trip quit, in case that main goroutine quit before cleanup had been done</strong>)</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">quit := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">string</span>)</span><br><span class="line">c := boring(<span class="string">&quot;Joe&quot;</span>, quit)</span><br><span class="line"><span class="keyword">for</span> i := rand.Intn(<span class="number">10</span>); i &gt;= <span class="number">0</span>; i-- &#123; fmt.Println(&lt;-c) &#125;</span><br><span class="line">quit &lt;- <span class="string">&quot;Bye!&quot;</span></span><br><span class="line">fmt.Printf(<span class="string">&quot;Joe says: %q\n&quot;</span>, &lt;-quit)</span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> c &lt;- fmt.Sprintf(<span class="string">&quot;%s: %d&quot;</span>, msg, i):</span><br><span class="line">    <span class="comment">// do nothing</span></span><br><span class="line"><span class="keyword">case</span> &lt;-quit:</span><br><span class="line">    cleanup()</span><br><span class="line">    quit &lt;- <span class="string">&quot;See you!&quot;</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Daisy-Chain"><a href="#Daisy-Chain" class="headerlink" title="Daisy Chain"></a>Daisy Chain</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph LR</span><br><span class="line">	routine1 --&gt; routine2 --left channel--&gt; routine3 --right channel--&gt; routine4 --&gt; routine5 --&gt; routine...</span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">(left, right <span class="keyword">chan</span> <span class="type">int</span>)</span></span> &#123;</span><br><span class="line">    left &lt;- <span class="number">1</span> + &lt;-right</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">const</span> n = <span class="number">10000</span></span><br><span class="line">    leftmost := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)</span><br><span class="line">    right := leftmost</span><br><span class="line">    left := leftmost</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; n; i++ &#123;</span><br><span class="line">        right = <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)</span><br><span class="line">        <span class="keyword">go</span> f(left, right)</span><br><span class="line">        left = right</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(c <span class="keyword">chan</span> <span class="type">int</span>)</span></span> &#123; c &lt;- <span class="number">1</span> &#125;(right)</span><br><span class="line">    fmt.Println(&lt;-leftmost)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="Rethinking-Classical-Concurrent-Patterns"><a href="#Rethinking-Classical-Concurrent-Patterns" class="headerlink" title="Rethinking Classical Concurrent Patterns"></a>Rethinking Classical Concurrent Patterns</h1><p>Two principles in go:</p>
<ol>
<li>Start goroutines when you have concurrent work</li>
<li>Share by communicating</li>
</ol>
<p>Other principles in go:</p>
<ol>
<li>Make concurrency internal detail.</li>
<li>Add concurrency on the caller side of the API.</li>
<li>Concurrency is not asynchronicity.</li>
</ol>
<h2 id="Asynchronous-API"><a href="#Asynchronous-API" class="headerlink" title="Asynchronous API"></a>Asynchronous API</h2><p>Concurrency is not asynchronicity.</p>
<p>An asynchronous API returns to the caller <strong>before its result is ready</strong>.</p>
<p>An asynchronous program is not necessarily concurrent: a program could call an asynchronous function and then sit idle waiting for the results.</p>
<p>There are several asynchronous patterns:</p>
<ul>
<li>asynchronous callback (deprecated)</li>
<li>future</li>
<li>producer-consumer queue</li>
</ul>
<h3 id="Asynchronous-Callback"><a href="#Asynchronous-Callback" class="headerlink" title="Asynchronous Callback"></a>Asynchronous Callback</h3><p>A callback is a simple function that’s passed as a value to another function, and will only be executed when the event happens.</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Fetch immediately returns, then fetches the item and </span></span><br><span class="line"><span class="comment">// invokes f in a goroutine when the item is available. </span></span><br><span class="line"><span class="comment">// If the item does not exist,</span></span><br><span class="line"><span class="comment">// Fetch invokes f on the zero Item.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Fetch</span><span class="params">(name <span class="type">string</span>, f <span class="keyword">func</span>(Item)</span></span>) &#123;</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        […]</span><br><span class="line">        f(item)</span><br><span class="line">    &#125;()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Future"><a href="#Future" class="headerlink" title="Future"></a>Future</h3><p>In the Future pattern, instead of returning the result, the function returns a proxy object that allows the caller to wait for the result at some later point.</p>
<p>The Go analogue to a <strong>Future</strong> is a <strong>single-element buffered channel</strong>.</p>
<p>To use Futures for concurrency, the caller must <strong>set up concurrent work before retrieving results</strong>.</p>
<p>If they retrieve the results too early, the program executes <em>sequentially instead of concurrently</em>.</p>
<p>the channel pattern seems to be more common than the function-based alternative</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Future: API, channel-based</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Fetch immediately returns a channel, then fetches </span></span><br><span class="line"><span class="comment">// the requested item and sends it on the channel. </span></span><br><span class="line"><span class="comment">// If the item does not exist,</span></span><br><span class="line"><span class="comment">// Fetch closes the channel without sending.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Fetch</span><span class="params">(name <span class="type">string</span>)</span></span> &lt;-<span class="keyword">chan</span> Item &#123;</span><br><span class="line">    c := <span class="built_in">make</span>(<span class="keyword">chan</span> Item, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        […]</span><br><span class="line">        c &lt;- item</span><br><span class="line">    &#125;()</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Future: The precise way, function-based</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Fetch</span><span class="params">(name <span class="type">string</span>)</span></span> (<span class="function"><span class="keyword">func</span><span class="params">()</span></span> Item) &#123;</span><br><span class="line">    item := <span class="built_in">new</span>(Item)</span><br><span class="line">    ready := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line">    […]</span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> Item &#123;</span><br><span class="line">        &lt;-ready</span><br><span class="line">        <span class="keyword">return</span> *item</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Future: caller side</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Right</span></span><br><span class="line">a := Fetch(<span class="string">&quot;a&quot;</span>) </span><br><span class="line">b := Fetch(<span class="string">&quot;b&quot;</span>)</span><br><span class="line">consume(&lt;-a, &lt;-b)</span><br><span class="line"></span><br><span class="line"><span class="comment">// False</span></span><br><span class="line">a := &lt;-Fetch(<span class="string">&quot;a&quot;</span>) <span class="comment">// routine get stalled on this line, so will lose concurrency</span></span><br><span class="line">b := &lt;-Fetch(<span class="string">&quot;b&quot;</span>)</span><br><span class="line">consume(a, b)</span><br></pre></td></tr></table></figure>

<h3 id="Producer–Consumer-Queue"><a href="#Producer–Consumer-Queue" class="headerlink" title="Producer–Consumer Queue"></a>Producer–Consumer Queue</h3><p>A producer–consumer queue also returns a channel, but the <strong>channel receives any number of results and is typically unbuffered</strong>.</p>
<p>A channel fed by one goroutine and read by another <strong>acts as a queue</strong>.</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Glob finds all items with names matching pattern</span></span><br><span class="line"><span class="comment">// and sends them on the returned channel.</span></span><br><span class="line"><span class="comment">// It closes the channel when all items have been sent. </span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Glob</span><span class="params">(pattern <span class="type">string</span>)</span></span> &lt;-<span class="keyword">chan</span> Item &#123;</span><br><span class="line">    c := <span class="built_in">make</span>(<span class="keyword">chan</span> Item)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        <span class="keyword">defer</span> <span class="built_in">close</span>(c)</span><br><span class="line">        <span class="keyword">for</span> […] &#123;</span><br><span class="line">            […]</span><br><span class="line">            c &lt;- item</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Producer-Consumer Queue: caller side</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item := <span class="keyword">range</span> Glob(<span class="string">&quot;[ab]*&quot;</span>) &#123;</span><br><span class="line">    [...]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Analysis-of-Asynchronous-API"><a href="#Analysis-of-Asynchronous-API" class="headerlink" title="Analysis of Asynchronous API"></a>Analysis of Asynchronous API</h3><p>Classical Benefit:</p>
<ul>
<li>Responsiveness : Avoid blocking UI and network threads<ul>
<li>Most other languages don’t multiplex across OS threads, and kernel schedulers can be unpredictable. So some popular languages and frameworks keep all of the UI or network logic on a single thread. If that thread makes a call that blocks for too long, the UI becomes choppy, or network latency spikes.</li>
<li>Since calls to asynchronous APIs by definition don’t block, they help to keep single-threaded programs responsive.</li>
<li>For go, goroutines are managed by go-runtime, not by kernel scheduler, so the first benefit doesn’t apply to go.</li>
</ul>
</li>
<li>Efficiency : Reduce  idle threads<ul>
<li>Threads are expensive</li>
<li>Languages that don’t multiplex over threads can use asynchronous APIs to keep threads busy, reducing the total number of threads — and context-switches</li>
<li>For go, goroutine is lightweight, it doesn’t spend too much on context switch.</li>
</ul>
</li>
<li>Efficiency : Reclaim stack frames<ul>
<li>Save frame space for other purpose.</li>
<li>For go, runtime resize and reallocate stack as needed. Besides, <strong>the storage location chosen by implementation is irrelevant to the semantics of the language</strong>.</li>
</ul>
</li>
<li>Concurrency : Initiate concurrent work<ul>
<li>Can be important for network RPCs</li>
</ul>
</li>
</ul>
<p>Classical Problems:</p>
<ul>
<li>Caller-Side Ambiguity</li>
</ul>
<h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;path/filepath&quot;</span></span><br><span class="line">	<span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Event <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"><span class="keyword">type</span> Item <span class="keyword">struct</span> &#123;</span><br><span class="line">	kind <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> items = <span class="keyword">map</span>[<span class="type">string</span>]Item&#123;</span><br><span class="line">	<span class="string">&quot;a&quot;</span>: Item&#123;<span class="string">&quot;gopher&quot;</span>&#125;,</span><br><span class="line">	<span class="string">&quot;b&quot;</span>: Item&#123;<span class="string">&quot;rabbit&quot;</span>&#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">doSlowThing</span><span class="params">()</span></span> &#123; time.Sleep(<span class="number">10</span> * time.Millisecond) &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">consume</span><span class="params">(a, b Item)</span></span> &#123;</span><br><span class="line">	fmt.Println(a, b)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Fetch</span><span class="params">(name <span class="type">string</span>)</span></span> &lt;-<span class="keyword">chan</span> Item &#123;</span><br><span class="line">	c := <span class="built_in">make</span>(<span class="keyword">chan</span> Item, <span class="number">1</span>)</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		item := items[name]</span><br><span class="line">		c &lt;- item</span><br><span class="line">	&#125;()</span><br><span class="line">	<span class="keyword">return</span> c</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Glob finds all items with names matching pattern</span></span><br><span class="line"><span class="comment">// and sends them on the returned channel.</span></span><br><span class="line"><span class="comment">// It closes the channel when all items have been sent.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Glob</span><span class="params">(pattern <span class="type">string</span>)</span></span> &lt;-<span class="keyword">chan</span> Item &#123;</span><br><span class="line">	c := <span class="built_in">make</span>(<span class="keyword">chan</span> Item)</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="keyword">defer</span> <span class="built_in">close</span>(c)</span><br><span class="line">		<span class="keyword">for</span> name, item := <span class="keyword">range</span> items &#123;</span><br><span class="line">			<span class="keyword">if</span> ok, _ := filepath.Match(pattern, name); !ok &#123;</span><br><span class="line">				<span class="keyword">continue</span></span><br><span class="line">			&#125;</span><br><span class="line">			c &lt;- item</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line">	<span class="keyword">return</span> c</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">for</span> item := <span class="keyword">range</span> Glob(<span class="string">&quot;[ab]*&quot;</span>) &#123;</span><br><span class="line">		fmt.Println(item)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Condition-Variable"><a href="#Condition-Variable" class="headerlink" title="Condition Variable"></a>Condition Variable</h2><h3 id="Condition-Variable-Analysis"><a href="#Condition-Variable-Analysis" class="headerlink" title="Condition Variable Analysis"></a>Condition Variable Analysis</h3><p>Problems:</p>
<ul>
<li>Spurious wakeups: Signal some or the threads are hard.</li>
<li>Forgotten signals: Forget to signal some threads when programming.</li>
<li>Starvation: long-running threads will get starved.</li>
<li>Unresponsive cancellation: While waiting for a condition, it may miss other event.</li>
</ul>
<p>Fundamentally, <strong>condition variables rely on communicating by sharing memory</strong>: they signal that a change has occurred, but leave it up to the signalled goroutine to check other shared variables to figure out what. On the other hand, the <strong>Go approach is to share by communicating</strong>.</p>
<h3 id="Semaphore-Sharing-by-Communicating"><a href="#Semaphore-Sharing-by-Communicating" class="headerlink" title="Semaphore : Sharing by Communicating"></a>Semaphore : Sharing by Communicating</h3><p>Go Benefits:</p>
<ul>
<li>Indicate the existence of new data.</li>
<li>Share data by communicating data.</li>
<li>Share things by communicating things.</li>
<li>Metadata are data too!</li>
<li>Mark transitions: mark that a broadcast by close a channel.</li>
</ul>
<p>Buffered channels –&gt; Semaphore pattern</p>
<h2 id="Worker-Pool"><a href="#Worker-Pool" class="headerlink" title="Worker Pool"></a>Worker Pool</h2><p>Benefits:</p>
<ul>
<li>Distribute work across threads<ul>
<li>Threads are heavyweight, worker pool allow reusing threads</li>
<li>Goroutines are lightweight, so it doesn’t apply to go</li>
</ul>
</li>
<li>Limit work in flight</li>
</ul>
<p>Principles:</p>
<ul>
<li><p>Start your goroutine only when you have concurrent work to do now</p>
</li>
<li><p>WaitGroup is enough –&gt; semaphore patterns</p>
</li>
</ul>
<h1 id="Go-Advanced-Concurrency-Patterns"><a href="#Go-Advanced-Concurrency-Patterns" class="headerlink" title="Go Advanced Concurrency Patterns"></a>Go Advanced Concurrency Patterns</h1><h2 id="Timeout-and-Multi-channels"><a href="#Timeout-and-Multi-channels" class="headerlink" title="Timeout and Multi-channels"></a>Timeout and Multi-channels</h2><h3 id="Timed-Channel-Operations"><a href="#Timed-Channel-Operations" class="headerlink" title="Timed Channel Operations"></a>Timed Channel Operations</h3><p>Keep trying doing something, but drop the ball when timeout</p>
<ul>
<li><code>context</code> implementation (more idiomatic)</li>
<li><code>time</code> implementation</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// context impl.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ToChanTimedContext</span><span class="params">(ctx context.Context, d time.Duration, message Type, c <span class="keyword">chan</span>&lt;- Type)</span></span> (written <span class="type">bool</span>) &#123;</span><br><span class="line">	ctx, cancel := context.WithTimeout(ctx, d)</span><br><span class="line">	<span class="keyword">defer</span> cancel()</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> c &lt;- message:</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">	<span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// time impl.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ToChanTimedTimer</span><span class="params">(d time.Duration, message Type, c <span class="keyword">chan</span>&lt;- Type)</span></span> (written <span class="type">bool</span>) &#123;</span><br><span class="line">	t := time.NewTimer(d)</span><br><span class="line">	<span class="keyword">defer</span> t.Stop()</span><br><span class="line">	<span class="keyword">select</span> &#123;</span><br><span class="line">	<span class="keyword">case</span> c &lt;- message:</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">	<span class="keyword">case</span> &lt;-t.C:</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="First-in-First-Served"><a href="#First-in-First-Served" class="headerlink" title="First in First Served"></a>First in First Served</h3><p>Sometimes you want to write the same message to many channels, writing to whichever is available first, but <strong>never writing the same message twice</strong> on the same channel.</p>
<ul>
<li>Use <code>select</code> statement to achieve so.</li>
<li>Use goroutines and waits</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// select statement</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">FirstComeFirstServeSelect</span><span class="params">(message Type, a, b <span class="keyword">chan</span> Type)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">2</span>; i++ &#123;</span><br><span class="line">        <span class="keyword">select</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> a &lt;- message:</span><br><span class="line">            a = <span class="literal">nil</span></span><br><span class="line">            <span class="keyword">case</span> b &lt;- message:</span><br><span class="line">            b = <span class="literal">nil</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// goroutine</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">FirstComeFirstServeGoroutine</span><span class="params">(message Type, a, b <span class="keyword">chan</span> Type)</span></span> &#123;</span><br><span class="line">    <span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">    wg.Add(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; a &lt;- message; wg.Done() &#125; ()</span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; b &lt;- message; wg.Done() &#125;</span><br><span class="line">    wg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>In this case performance might matter, and at the time of writing the solution that spawns goroutines takes almost 4 times more than the one with <code>select</code>.</p>
<p>If the amount of channels is not known at compile time, the first solution becomes trickier, but it is still possible, while the second one stays basically unchanged.</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">FirstComeFirstServedGoroutinesVariadic</span><span class="params">(message Type, chs ...<span class="keyword">chan</span>&lt;- Type)</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">	wg.Add(<span class="built_in">len</span>(chs))</span><br><span class="line">	<span class="keyword">for</span> _, c := <span class="keyword">range</span> chs &#123;</span><br><span class="line">		c := c</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c &lt;- message; wg.Done() &#125;()</span><br><span class="line">	&#125;</span><br><span class="line">	wg.Wait()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">FirstComeFirstServedSelectVariadic</span><span class="params">(message Type, chs ...<span class="keyword">chan</span>&lt;- Type)</span></span> &#123;</span><br><span class="line">	cases := <span class="built_in">make</span>([]reflect.SelectCase, <span class="built_in">len</span>(chs))</span><br><span class="line">	<span class="keyword">for</span> i, ch := <span class="keyword">range</span> chs &#123;</span><br><span class="line">		cases[i] = reflect.SelectCase&#123;</span><br><span class="line">			Dir:  reflect.SelectSend,</span><br><span class="line">			Chan: reflect.ValueOf(ch),</span><br><span class="line">			Send: reflect.ValueOf(message),</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(chs); i++ &#123;</span><br><span class="line">		chosen, _, _ := reflect.Select(cases)</span><br><span class="line">		cases[chosen].Chan = reflect.ValueOf(<span class="literal">nil</span>)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>The solution using reflection is almost two orders of magnitude slower than the one with goroutines and unreadable.</p>
<h3 id="First-in-First-Serve-with-Timeout"><a href="#First-in-First-Serve-with-Timeout" class="headerlink" title="First in First Serve with Timeout"></a>First in First Serve with Timeout</h3><p>There are two solutions in case you want to try a several sends and abort if it takes too long.</p>
<ul>
<li><code>time + select</code> : better if account of channels are known at compile time.</li>
<li><code>context + go</code> : channels are unknown at compile time.</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// time + select</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ToChansTimedTimerSelect</span><span class="params">(d time.Duration, message Type, a, b <span class="keyword">chan</span> Type)</span></span> (written <span class="type">int</span>) &#123;</span><br><span class="line">	t := time.NewTimer(d)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">2</span>; i++ &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> a &lt;- message:</span><br><span class="line">			a = <span class="literal">nil</span></span><br><span class="line">		<span class="keyword">case</span> b &lt;- message:</span><br><span class="line">			b = <span class="literal">nil</span></span><br><span class="line">		<span class="keyword">case</span> &lt;-t.C:</span><br><span class="line">			<span class="keyword">return</span> i</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	t.Stop()</span><br><span class="line">	<span class="keyword">return</span> <span class="number">2</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// context + go</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ToChansTimedContextGoroutines</span><span class="params">(ctx context.Context, d time.Duration, message Type, ch ...<span class="keyword">chan</span> Type)</span></span> (written <span class="type">int</span>) &#123;</span><br><span class="line">	ctx, cancel := context.WithTimeout(ctx, d)</span><br><span class="line">	<span class="keyword">defer</span> cancel()</span><br><span class="line">	<span class="keyword">var</span> (</span><br><span class="line">		wr <span class="type">int32</span></span><br><span class="line">		wg sync.WaitGroup</span><br><span class="line">	)</span><br><span class="line">	wg.Add(<span class="built_in">len</span>(ch))</span><br><span class="line">	<span class="keyword">for</span> _, c := <span class="keyword">range</span> ch &#123;</span><br><span class="line">		c := c</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			<span class="keyword">defer</span> wg.Done()</span><br><span class="line">			<span class="keyword">select</span> &#123;</span><br><span class="line">			<span class="keyword">case</span> c &lt;- message:</span><br><span class="line">				atomic.AddInt32(&amp;wr, <span class="number">1</span>)</span><br><span class="line">			<span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line">	wg.Wait()</span><br><span class="line">	<span class="keyword">return</span> <span class="type">int</span>(wr)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Timer"><a href="#Timer" class="headerlink" title="Timer"></a>Timer</h2><h3 id="time-Ticker"><a href="#time-Ticker" class="headerlink" title="time.Ticker"></a>time.Ticker</h3><p>NewTicker returns a new Ticker containing a channel that will send the current time on the channel after each tick. The period of the ticks is specified by the duration argument. </p>
<p>The ticker will adjust the time interval or drop ticks to make up for slow receivers. The duration d must be greater than zero; if not, NewTicker will panic. </p>
<p>Stop the ticker to release associated resources.</p>
<p>Some caveats:</p>
<ul>
<li><strong>Sends will drop all unread values if <code>C</code> already has one message in it</strong>.</li>
<li>It <strong>must be stopped</strong>: the GC will not collect it otherwise.</li>
<li>Setting <code>C</code> is useless: <strong>messages will still be sent on the original channel</strong>.</li>
</ul>
<h3 id="time-Tick"><a href="#time-Tick" class="headerlink" title="time.Tick"></a>time.Tick</h3><p>Tick is a convenience wrapper for NewTicker providing access to the ticking channel only.</p>
<p>But this is something that should never be used unless you plan to carry the returned <code>chan</code> around and keep using it for the <strong>entire lifetime of the program</strong>.</p>
<p><strong>Because the underlying Ticker cannot be recovered by the garbage collector; it “leaks”</strong>.</p>
<h3 id="time-Timer"><a href="#time-Timer" class="headerlink" title="time.Timer"></a>time.Timer</h3><p>The Timer type represents a single event. <em>When the Timer expires, the current time will be sent on C</em>, unless the Timer was created by AfterFunc. <em><strong>A Timer must be created with NewTimer or AfterFunc</strong></em>.</p>
<p><code>Reset</code> changes the timer to expire after duration d. It returns true if the timer had been active, false if the timer had expired or been stopped.</p>
<p><em><strong>For a Timer created with NewTimer, Reset should be invoked only on stopped or expired timers with drained channels</strong></em>.</p>
<p>Some caveat:</p>
<ul>
<li><code>C</code> cannot be set by user although it is exported.</li>
<li><code>Timer</code> returned by <code>AfterFunc</code> doesn’t use <code>C</code> at all.</li>
<li><code>C</code> will not be closed even after Stop the Timer</li>
<li><code>Stop</code> is safe only after <code>New</code> and <code>Reset</code>.</li>
<li><code>Reset</code> is only valid after <code>Stop</code>.</li>
<li>Received value is valid only if channel is drained after each <code>Stop</code>.</li>
<li>The channel should be drained if and only if the channel has not been read yet.</li>
</ul>
<p><code>time.Afterfunc</code>:</p>
<ul>
<li>AfterFunc waits for the duration to elapse and then calls f in its own goroutine. It returns a Timer that <strong>can be used to cancel the call using its Stop method</strong>.</li>
<li>when calling <code>Stop</code>, if <code>false</code> is returned, it means that stopping failed and the function was already started.</li>
</ul>
<p><code>time.NewTimer</code>:</p>
<ul>
<li><p>NewTimer creates a new Timer that will send the current time on its channel after at least duration d.</p>
</li>
<li><p>This means that there is no way to construct a valid <code>Timer</code> without starting it. If you need to construct one for future re-use, you either do it lazily or you have to create and stop it, which can be done with this code:</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">t := time.NewTimer(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">if</span> !t.Stop() &#123;</span><br><span class="line">	&lt;-t.C</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p><code>time.Stop</code>:</p>
<ul>
<li><p>Stop prevents the Timer from firing. It returns <strong>true</strong> if the <strong>call stops the timer</strong>, <strong>false</strong> if the timer has <em><strong>already expired</strong></em> <strong>or</strong> <em><strong>been stopped</strong></em>.</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//* not thread safe</span></span><br><span class="line"><span class="keyword">if</span> !t.Stop() &#123;</span><br><span class="line">	&lt;-t.C</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p><code>time.Reset</code>:</p>
<ul>
<li>Note that it is not possible to use Reset’s return value correctly, as there is a race condition between draining the channel and the new timer expiring. <strong>Reset should always be invoked on stopped or expired channels</strong>.</li>
<li>You cannot use <code>Stop</code> nor <code>Reset</code> concurrently <em>with other receives from the channel</em>, and in order for the value sent on <code>C</code> to be valid, <strong><code>C</code> should be drained exactly once before each <code>Reset</code></strong>.</li>
</ul>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Timer API</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Timer <span class="keyword">struct</span> &#123;</span><br><span class="line">	C &lt;-<span class="keyword">chan</span> Time</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">AfterFunc</span><span class="params">(d Duration, f <span class="keyword">func</span>()</span></span>) *Timer</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewTimer</span><span class="params">(d Duration)</span></span> *Timer</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*Timer)</span></span> Stop(<span class="type">bool</span>)</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*Timer)</span></span> Reset(d Duration) <span class="type">bool</span></span><br></pre></td></tr></table></figure>

<p><img src="D:\Blog\source_images\image-20221216234927956.png" alt="image-20221216234927956"></p>
<h3 id="time-After"><a href="#time-After" class="headerlink" title="time.After"></a>time.After</h3><p>This is basically the same concept of <code>Tick</code> but instead of hiding a <code>Ticker</code>, hides a <code>Timer</code>. This is slightly better because once the timer will fire, it will be collected. Please note that timers use 1-buffered channels, so they can fire even if no one is receiving.</p>
<p>But if you care about performance and you want to be able to cancel the call, you should not use <code>After</code>.</p>
<h2 id="Some-Tricks"><a href="#Some-Tricks" class="headerlink" title="Some Tricks"></a>Some Tricks</h2><ul>
<li>For-select loop</li>
<li>Service channel, reply channels (channel of channel)</li>
<li><code>nil</code> channel for select cases</li>
</ul>
<h1 id="Example-Search-Engine"><a href="#Example-Search-Engine" class="headerlink" title="Example : Search Engine"></a>Example : Search Engine</h1><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;math/rand&quot;</span></span><br><span class="line">	<span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Result <span class="keyword">struct</span> &#123;</span><br><span class="line">	res <span class="type">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Search <span class="function"><span class="keyword">func</span><span class="params">(query <span class="type">string</span>)</span></span> Result</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">FakeSearch</span><span class="params">(kind <span class="type">string</span>)</span></span> Search &#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(query <span class="type">string</span>)</span></span> Result &#123;</span><br><span class="line">		time.Sleep(time.Duration(rand.Intn(<span class="number">100</span>)) * time.Millisecond)</span><br><span class="line">		<span class="keyword">return</span> Result&#123;fmt.Sprintf(<span class="string">&quot;%v returns %v&quot;</span>, kind, query)&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">	Web    = FakeSearch(<span class="string">&quot;Web&quot;</span>)</span><br><span class="line">	Image  = FakeSearch(<span class="string">&quot;Image&quot;</span>)</span><br><span class="line">	Video  = FakeSearch(<span class="string">&quot;Video&quot;</span>)</span><br><span class="line">	Web1   = FakeSearch(<span class="string">&quot;Web&quot;</span>)</span><br><span class="line">	Image1 = FakeSearch(<span class="string">&quot;Image&quot;</span>)</span><br><span class="line">	Video1 = FakeSearch(<span class="string">&quot;Video&quot;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Generator</span><span class="params">(query <span class="type">string</span>)</span></span> <span class="keyword">chan</span> Result &#123;</span><br><span class="line">	ch := <span class="built_in">make</span>(<span class="keyword">chan</span> Result)</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; ch &lt;- Web(query) &#125;()</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; ch &lt;- Image(query) &#125;()</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; ch &lt;- Video(query) &#125;()</span><br><span class="line">	<span class="keyword">return</span> ch</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">timeout edition of google search engine</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">GoogleTimeout</span><span class="params">(query <span class="type">string</span>)</span></span> []Result &#123;</span><br><span class="line">	results := <span class="built_in">make</span>([]Result, <span class="number">0</span>)</span><br><span class="line">	ch := Generator(query)</span><br><span class="line">	timeout := time.After(<span class="number">80</span> * time.Millisecond)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">3</span>; i++ &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> res := &lt;-ch:</span><br><span class="line">			results = <span class="built_in">append</span>(results, res)</span><br><span class="line">			fmt.Println(res)</span><br><span class="line">		<span class="keyword">case</span> &lt;-timeout:</span><br><span class="line">			<span class="keyword">return</span> results</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> results</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">SearchWithReplicas</span><span class="params">(query <span class="type">string</span>, replicas ...Search)</span></span> Result &#123;</span><br><span class="line">	ch := <span class="built_in">make</span>(<span class="keyword">chan</span> Result)</span><br><span class="line">	<span class="keyword">for</span> _, search := <span class="keyword">range</span> replicas &#123;</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(search <span class="keyword">func</span>(query <span class="type">string</span>)</span></span> Result) &#123;</span><br><span class="line">			ch &lt;- search(query)</span><br><span class="line">		&#125;(search)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> &lt;-ch</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Google</span><span class="params">(query <span class="type">string</span>)</span></span> []Result &#123;</span><br><span class="line">	<span class="keyword">var</span> results []Result</span><br><span class="line">	ch := <span class="built_in">make</span>(<span class="keyword">chan</span> Result)</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; ch &lt;- SearchWithReplicas(query, Web, Web1) &#125;()</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; ch &lt;- SearchWithReplicas(query, Image, Image1) &#125;()</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; ch &lt;- SearchWithReplicas(query, Video, Video1) &#125;()</span><br><span class="line">	timeout := time.After(time.Duration(<span class="number">80</span>) * time.Millisecond)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">3</span>; i++ &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> res := &lt;-ch:</span><br><span class="line">			results = <span class="built_in">append</span>(results, res)</span><br><span class="line">		<span class="keyword">case</span> &lt;-timeout:</span><br><span class="line">			<span class="built_in">panic</span>(<span class="string">&quot;timeout&quot;</span>)</span><br><span class="line">			<span class="comment">// return results</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> results</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	rand.Seed(time.Now().UnixNano())</span><br><span class="line">	start := time.Now()</span><br><span class="line">	results := Google(<span class="string">&quot;who are you?&quot;</span>)</span><br><span class="line">	elapsed := time.Since(start)</span><br><span class="line">	fmt.Println(elapsed)</span><br><span class="line">	fmt.Println(results)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Example-Load-Balancer"><a href="#Example-Load-Balancer" class="headerlink" title="Example : Load Balancer"></a>Example : Load Balancer</h1><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">this is a pseudo code for load balancer</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;container/heap&quot;</span></span><br><span class="line">	<span class="string">&quot;math/rand&quot;</span></span><br><span class="line">	<span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Requester</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Request <span class="keyword">struct</span> &#123;</span><br><span class="line">	fn <span class="function"><span class="keyword">func</span><span class="params">()</span></span> <span class="type">int</span> <span class="comment">// the operation to perform</span></span><br><span class="line">	c  <span class="keyword">chan</span> <span class="type">int</span>   <span class="comment">// the channel to return results</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">requester</span><span class="params">(works <span class="keyword">chan</span> Request)</span></span> &#123;</span><br><span class="line">	c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="type">int</span>)</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		time.Sleep(time.Duration(rand.Intn(<span class="number">80</span>)) * time.Millisecond) <span class="comment">//* to emulate load time</span></span><br><span class="line">		works &lt;- Request&#123;workFn, c&#125;</span><br><span class="line">		result := &lt;-c</span><br><span class="line">		futherProcess(result)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Worker</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Worker <span class="keyword">struct</span> &#123;</span><br><span class="line">	requests <span class="keyword">chan</span> Request</span><br><span class="line">	pending  <span class="type">int</span></span><br><span class="line">	index    <span class="type">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *Worker)</span></span> work(done <span class="keyword">chan</span> *Worker) &#123;</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		req := &lt;-w.requests</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(req Request)</span></span> &#123;</span><br><span class="line">			req.c &lt;- req.fn()</span><br><span class="line">			done &lt;- w</span><br><span class="line">		&#125;(req)</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Balacer</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Pool []*Worker</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Balancer <span class="keyword">struct</span> &#123;</span><br><span class="line">	pool Pool</span><br><span class="line">	done <span class="keyword">chan</span> *Worker</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b *Balancer)</span></span> balancer(work <span class="keyword">chan</span> Request) &#123;</span><br><span class="line">	<span class="keyword">for</span> &#123;</span><br><span class="line">		<span class="keyword">select</span> &#123;</span><br><span class="line">		<span class="keyword">case</span> req := &lt;-work:</span><br><span class="line">			b.dispatch(req)</span><br><span class="line">		<span class="keyword">case</span> w := &lt;-b.done:</span><br><span class="line">			b.complete(w)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b *Balancer)</span></span> dispatch(req Request) &#123;</span><br><span class="line">	w := heap.Pop(&amp;b.pool).(*Worker)</span><br><span class="line">	w.requests &lt;- req</span><br><span class="line">	w.pending++</span><br><span class="line">	heap.Push(&amp;b.pool, w)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b *Balancer)</span></span> complete(w *Worker) &#123;</span><br><span class="line">	w.pending--</span><br><span class="line">	heap.Remove(&amp;b.pool, w.index)</span><br><span class="line">	heap.Push(&amp;b.pool, w)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">const</span> poolSize = <span class="number">30</span></span><br><span class="line">	<span class="keyword">var</span> requests <span class="keyword">chan</span> Request = <span class="built_in">make</span>(<span class="keyword">chan</span> Request)</span><br><span class="line">	<span class="keyword">go</span> requester(requests) <span class="comment">//* load request and generate work</span></span><br><span class="line">	<span class="keyword">var</span> b Balancer = Balancer&#123;<span class="built_in">make</span>(Pool, <span class="number">0</span>), <span class="built_in">make</span>(<span class="keyword">chan</span> *Worker)&#125;</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; poolSize; i++ &#123;</span><br><span class="line">		b.pool = <span class="built_in">append</span>(b.pool, &amp;Worker&#123;requests, <span class="number">0</span>, i&#125;)</span><br><span class="line">		<span class="keyword">go</span> b.pool[i].work(b.done)</span><br><span class="line">	&#125; <span class="comment">//* generate workers</span></span><br><span class="line"></span><br><span class="line">	b.balancer(requests) <span class="comment">//* do load balance things</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Go</tag>
        <tag>Concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title>RISC-V</title>
    <url>/2022/11/17/RISC-V/</url>
    <content><![CDATA[<p>CSR (Control and Status Registers) : 64bits</p>
<span id="more"></span>

<table>
<thead>
<tr>
<th>register</th>
<th>function</th>
</tr>
</thead>
<tbody><tr>
<td>mscratch</td>
<td>Machine Scratch。保存机器模式的栈顶指针，这一点在离开机器模式进入低特权级模式（如监管模式）时非常重要，因为一旦在低特权级模式发生异常，将可能会回到机器模式处理，这时机器模式需要有自己的栈来保存M模式下的执行所调用的函数参数和返回地址。</td>
</tr>
<tr>
<td>mstatus</td>
<td>Machine Status。保存机器状态的寄存器。</td>
</tr>
<tr>
<td>mtvec</td>
<td>Machine Trap Vector。指向中断处理函数的入口地址。</td>
</tr>
<tr>
<td>mepc</td>
<td>Machine Exception PC。指向发生异常的那条指令的地址。</td>
</tr>
<tr>
<td>mcause</td>
<td>Machine Cause。发生中断的原因，如果发生的中断是异常，其最高位为0，低位为异常编号；如果发生的是其他类型的中断，则其最高位为1，低位为中断编号。</td>
</tr>
<tr>
<td>mtval</td>
<td>Machine Trap Value。异常发生时，附带的参数值。例如，当缺页异常发生时，mtval的值就是程序想要访问的虚地址。</td>
</tr>
<tr>
<td>mie</td>
<td>Machine Interrupt Enable。中断开启寄存器。</td>
</tr>
<tr>
<td>mip</td>
<td>Machine Interrupt Pending。中断等待寄存器。</td>
</tr>
<tr>
<td>mideleg</td>
<td>Machine Interrupt Delegation Registers。中断代理寄存器。</td>
</tr>
<tr>
<td>medeleg</td>
<td>Machine Exception Delegation Registers。异常代理寄存器。</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>寄存器</th>
<th>作用</th>
</tr>
</thead>
<tbody><tr>
<td>sscratch</td>
<td>Supervisor Scratch。保存监管模式的栈顶指针，这一点在离开机器模式进入低特权级模式（如用户模式）时非常重要，因为一旦在低特权级模式发生异常，将可能会回到监管模式处理（假设已通过异常授权），这时监管模式需要用自己的栈保存程序执行的返回地址等。</td>
</tr>
<tr>
<td>sstatus</td>
<td>Supervisor Status。保存监管状态的寄存器。</td>
</tr>
<tr>
<td>stvec</td>
<td>Supervisor Trap Vector。指向监管模式中断处理函数的入口地址。</td>
</tr>
<tr>
<td>sepc</td>
<td>Supervisor Exception PC。指向发生异常的那条指令的地址。</td>
</tr>
<tr>
<td>scause</td>
<td>Supervisor Cause。发生中断的原因，如果发生的中断是异常，其最高位为0，低位为异常编号；如果发生的是其他中断其最高位为1，低位为中断编号。</td>
</tr>
<tr>
<td>stval</td>
<td>Supervisor Trap Value。异常发生时，附带的参数值。例如，当缺页异常发生时，mtval的值就是程序想要访问的虚地址。</td>
</tr>
<tr>
<td>sie</td>
<td>Supervisor Interrupt Enable。中断开启寄存器。</td>
</tr>
<tr>
<td>sip</td>
<td>Supervisor Interrupt Pending。中断等待寄存器。</td>
</tr>
<tr>
<td>sideleg</td>
<td>Supervisor Interrupt Delegation Registers。中断代理寄存器。</td>
</tr>
<tr>
<td>sedeleg</td>
<td>Supervisor Exception Delegation Registers。异常代理寄存器。</td>
</tr>
</tbody></table>
<p>CSR 读写指令</p>
<table>
<thead>
<tr>
<th>指令</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>csrr rd, csr</td>
<td>Control and Status Register Read，<strong>读</strong>CSR指令。 把csr寄存器中的值写入到rd寄存器中。</td>
</tr>
<tr>
<td>csrw csr, rs1</td>
<td>Control and Status Register Write，<strong>写</strong>CSR指令。 把rs1的值写到csr寄存器中。</td>
</tr>
<tr>
<td>csrs csr, rs1</td>
<td>Control and Status Register Set，<strong>设置</strong>CSR指令。 对于rs1中每一个为1的位，将csr寄存器中对应位置位。</td>
</tr>
<tr>
<td>csrc csr, rs1</td>
<td>Control and Status Register Clear，<strong>清除</strong>CSR指令。 对于rs1中每一个为1的位，将csr寄存器中对应位清零。</td>
</tr>
<tr>
<td>csrrs rd, csr, rs1</td>
<td>Control and Status Register Read and Set，<strong>读后置位</strong>CSR指令。 记控制寄存器中的值为t，把t和寄存器rs1按位或的结果写入csr寄存器，再把t写入rd寄存器。</td>
</tr>
<tr>
<td>csrrc rd, csr, rs1</td>
<td>Control and Status Register Read and Clear，<strong>读后清除</strong>CSR指令。 记控制寄存器中的值为t，把t和寄存器rs1中的值按位与的结果写入csr寄存器，再把t写入rd寄存器。</td>
</tr>
<tr>
<td>csrrw rd, csr, rs1</td>
<td>Control and Status Register Read and Write，<strong>读后写</strong>CSR指令。 记控制寄存器中的值为t，把寄存器rs1的值写入csr寄存器，再把t写入rd寄存器。</td>
</tr>
</tbody></table>
]]></content>
      <tags>
        <tag>RISC-V</tag>
      </tags>
  </entry>
</search>
